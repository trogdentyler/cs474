{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gjv_hsXTN3P"
      },
      "source": [
        "# Lab 9: Stable Diffusion\n",
        "In this lab, you will have the chance to implement several key parts of a State of the Art (SOTA) model! We will work with the Stable Diffusion model pipeline. Stable Diffusion is a text-to-image generative model--and more: It can also be adapted for image-to-image translation, video generation, unconditioned image generation,...\n",
        "\n",
        "*   [HuggingFace repository](https://huggingface.co/CompVis/stable-diffusion-v1-4)\n",
        "*   [GitHub repository](https://github.com/CompVis/stable-diffusion)\n",
        "*   [Paper on arxiv](https://arxiv.org/abs/2112.10752)\n",
        "\n",
        "Due to hardware constraints (training this model is very memory intensive), you will not train the model, but will load pretrained weights from the Stable Diffusion repository on [huggingface.co](huggingface.co). Then, you can run inference with the pipeline and generate some awesome images!\n",
        "\n",
        "The pipeline is comprised of several fairly complex models. The parts you will implement are as follows:\n",
        "\n",
        "*    The UNet forward function (a UNet like from the cancer detection lab that uses attention like from the transformers lab)\n",
        "*    DDIM scheduler--the sampling mechanism\n",
        "*    Loading the pre-trained VAE\n",
        "\n",
        "Lastly, because the diffusers library is open source, of course it's stipulated that you **not** reference their code for the parts we ask you to implement.\n",
        "\n",
        "#### Rubric\n",
        "\n",
        "\n",
        "*   Part 0: Log in to HF (10%)\n",
        "*   Part 1: Comment what is hapening in the `forward()` function of the UNet with cross attention (20%)\n",
        "*   Part 2: Implement the DDIM scheduler (40%)\n",
        "*   Part 3: Load the pretrained models and comment what is happening in the StableDiffusionPipeline (10%)\n",
        "*   Part 4: Generate an awesome image and answer a few questions (10%)\n",
        "*   Neat and clean code (10%)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYAa2uRXVGOo"
      },
      "source": [
        "### Part 0: Initial setup and logging in to HuggingFace\n",
        "\n",
        "If you're not familiar with HuggingFace, it's like a GitHub specifically for deep learning. You can find datasets, models, and more there. We will need it because it has pretrained weights for the models we will use, because training is too memory intensive to manage in Colab.\n",
        "\n",
        "The repo we will use is [\"CompVis/stable-diffusion-v1-4\"](https://huggingface.co/CompVis/stable-diffusion-v1-4). To access this repo, you must create a HuggingFace account, then go to this link and accept some terms. You will also need to create a User Access Token. Finally, you can run the cell below, paste the token, and hit login. (It will cache the token so you should only need to do this once per session.) [This tutorial](https://huggingface.co/docs/hub/security-tokens) covers access tokens on HuggingFace.\n",
        "\n",
        "If the login widget is not working and you are not using Google Chrome, try on Chrome before resorting to other debugging techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "upQBu-sRJJdq"
      },
      "outputs": [],
      "source": [
        "# INSTALLS\n",
        "%%capture\n",
        "\n",
        "!pip install diffusers          # Contains the main classes we will be using\n",
        "!pip install transformers       # Used in pipeline to process text prompt\n",
        "!pip install huggingface_hub    # For logging in to huggingface \n",
        "!pip install ftfy               # For text tokenizing, used by the pipeline\n",
        "!pip install accelerate         # Helps run in low memory mode -- needed though not explicitly used "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MtFjFMaOSNgQ"
      },
      "outputs": [],
      "source": [
        "# GENERIC IMPORTS\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "2d1bd8c25c604e649acb52b5f08677b6",
            "4ee4cb866125490aaad3aa640e055ef1",
            "1dc4d0f83c354194aca66149aa09d919",
            "53798a1f893248aa8885ca4dcca84ed0",
            "be19c716c95b4ec196d8455277cc5159",
            "6e6f1f36ad9b4ebfbc377a8e647caa30",
            "7f7d402e559b4510a1c6afcd4feb8fbd",
            "8738df5db90b4a438a8467309b8f2189",
            "fd7f395c1e224e9480542f1f41b3c6ec",
            "c220a2a670684b328c832836702dead0",
            "08c1aae8f6b04204b8b5b62f719c395f",
            "7c5bbd2b9b8f4e8f9d02bbb1215142b5",
            "1d5afcaa50fe485a8663d00078233e6f",
            "f4c0475974d04c2aaa6d29ad255aacf5",
            "01d0173897364af2ad3b7594fe304933",
            "5047288108524606abbf9418d7820a99",
            "ee1e0d9187c34a8eab8cfc0c68d1b05c"
          ]
        },
        "id": "ciG07tT2JWT6",
        "outputId": "afb64f7f-a3fe-46ce-bf51-506da0b6b753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid.\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# LOG IN TO HUGGINGFACE\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-vrH2A3TPMO"
      },
      "source": [
        "### Part 1: UNet with attention\n",
        "\n",
        "Stable Diffusion uses a UNet as part of its training and inference pipeline. You might not be familiar with the term pipeline as used here--it just means a singular object that will create the needed submodels, and when called, it coordinates calling each submodel, so that there's just one object that will take in a text prompt and output a photo result. This way, the user just interacts with one object, rather than having to instantiate several objects and coordinate them.\n",
        "\n",
        "What does this pipeline do? In Stable Diffusion there are quite a few moving parts. The flow from the text prompt to the final images is:\n",
        "\n",
        "1.   Tokenize the text (with some tokenizer)\n",
        "2.   Encode the text (with a pretrained NLP model like a transformer)\n",
        "3.   Generate initial latent space representation of the generated image (this will be pure noise at the beginning)\n",
        "4. Process the latent space representation with a UNet that has been trained to predict what noise was added to its input in the latest timestep. The UNet attends to the encoded text as it does so, making it conditioned via attention.\n",
        "5.   Subtract the noise prediction from $x_t$ to get the prediction for $x_{t-1}$.\n",
        "6.   Repeat steps 4 and 5 many times.\n",
        "7.   Take the final latent space representation of the generated image and decode it to pixel space (using something like a VAE).\n",
        "8.   Run through a \"SafetyChecker\" to make sure there is no NSFW content; if there is, return a black image instead and raise a flag.\n",
        "\n",
        "In this lab, we subclass from classes defined in the actual Stable Diffusion source code; this gives us several auxiliary functions that are somewhat unenlightening to implement, like loading the pretrained weights from huggingface. We will then override the functions that we do want to implement. \n",
        "\n",
        "In this part, we will override the forward function of the UNet so you have a chance to implement it. Follow the comments throughout, or it could be difficult.\n",
        "\n",
        "This part gives a good example of how attention is used in SOTA models. It is used, not only to process the text in the transformer, but also to condition the denoising model on the processed text. Feel free to look at the source code for the UNet2DBlocks to see how the attention is calculated. \n",
        "\n",
        "Read the following cell, run it, and read the description in the subsequent cell:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DESCRIBE UNET STRUCTURE TO HELP WITH NEXT CELL\n",
        "\n",
        "from diffusers.models.unet_2d_condition import *\n",
        "from diffusers.models.unet_2d_blocks import * \n",
        "\n",
        "tmp = UNet2DConditionModel()\n",
        "\n",
        "print(\"Items and methods from the UNet2DConditionModel:\")\n",
        "for item in dir(tmp):\n",
        "  if not item.startswith(\"__\"):\n",
        "    print(f\"{item} is type {type(getattr(tmp, item))}\")\n",
        "\n",
        "del tmp"
      ],
      "metadata": {
        "id": "jsbVWlMuVCNM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685ba809-f1dc-4359-f98a-b4319e4d85aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Items and methods from the UNet2DConditionModel:\n",
            "T_destination is type <class 'typing.TypeVar'>\n",
            "_apply is type <class 'method'>\n",
            "_automatically_saved_args is type <class 'list'>\n",
            "_backward_hooks is type <class 'collections.OrderedDict'>\n",
            "_buffers is type <class 'collections.OrderedDict'>\n",
            "_call_impl is type <class 'method'>\n",
            "_deprecated_kwargs is type <class 'list'>\n",
            "_dict_from_json_file is type <class 'method'>\n",
            "_forward_hooks is type <class 'collections.OrderedDict'>\n",
            "_forward_pre_hooks is type <class 'collections.OrderedDict'>\n",
            "_get_backward_hooks is type <class 'method'>\n",
            "_get_init_keys is type <class 'function'>\n",
            "_get_name is type <class 'method'>\n",
            "_internal_dict is type <class 'diffusers.configuration_utils.FrozenDict'>\n",
            "_is_full_backward_hook is type <class 'NoneType'>\n",
            "_load_from_state_dict is type <class 'method'>\n",
            "_load_pretrained_model is type <class 'method'>\n",
            "_load_state_dict_post_hooks is type <class 'collections.OrderedDict'>\n",
            "_load_state_dict_pre_hooks is type <class 'collections.OrderedDict'>\n",
            "_maybe_warn_non_full_backward_hook is type <class 'method'>\n",
            "_modules is type <class 'collections.OrderedDict'>\n",
            "_named_members is type <class 'method'>\n",
            "_non_persistent_buffers_set is type <class 'set'>\n",
            "_parameters is type <class 'collections.OrderedDict'>\n",
            "_register_load_state_dict_pre_hook is type <class 'method'>\n",
            "_register_state_dict_hook is type <class 'method'>\n",
            "_replicate_for_data_parallel is type <class 'method'>\n",
            "_save_to_state_dict is type <class 'method'>\n",
            "_set_gradient_checkpointing is type <class 'method'>\n",
            "_slow_forward is type <class 'method'>\n",
            "_state_dict_hooks is type <class 'collections.OrderedDict'>\n",
            "_supports_gradient_checkpointing is type <class 'bool'>\n",
            "_version is type <class 'int'>\n",
            "act_fn is type <class 'str'>\n",
            "add_module is type <class 'method'>\n",
            "apply is type <class 'method'>\n",
            "attention_head_dim is type <class 'int'>\n",
            "attn_processors is type <class 'dict'>\n",
            "bfloat16 is type <class 'method'>\n",
            "block_out_channels is type <class 'tuple'>\n",
            "buffers is type <class 'method'>\n",
            "center_input_sample is type <class 'bool'>\n",
            "children is type <class 'method'>\n",
            "class_embed_type is type <class 'NoneType'>\n",
            "class_embedding is type <class 'NoneType'>\n",
            "config is type <class 'diffusers.configuration_utils.FrozenDict'>\n",
            "config_name is type <class 'str'>\n",
            "conv_act is type <class 'torch.nn.modules.activation.SiLU'>\n",
            "conv_in is type <class 'torch.nn.modules.conv.Conv2d'>\n",
            "conv_in_kernel is type <class 'int'>\n",
            "conv_norm_out is type <class 'torch.nn.modules.normalization.GroupNorm'>\n",
            "conv_out is type <class 'torch.nn.modules.conv.Conv2d'>\n",
            "conv_out_kernel is type <class 'int'>\n",
            "cpu is type <class 'method'>\n",
            "cross_attention_dim is type <class 'int'>\n",
            "cuda is type <class 'method'>\n",
            "device is type <class 'torch.device'>\n",
            "disable_gradient_checkpointing is type <class 'method'>\n",
            "disable_xformers_memory_efficient_attention is type <class 'method'>\n",
            "double is type <class 'method'>\n",
            "down_block_types is type <class 'tuple'>\n",
            "down_blocks is type <class 'torch.nn.modules.container.ModuleList'>\n",
            "downsample_padding is type <class 'int'>\n",
            "dtype is type <class 'torch.dtype'>\n",
            "dual_cross_attention is type <class 'bool'>\n",
            "dump_patches is type <class 'bool'>\n",
            "enable_gradient_checkpointing is type <class 'method'>\n",
            "enable_xformers_memory_efficient_attention is type <class 'method'>\n",
            "eval is type <class 'method'>\n",
            "extra_repr is type <class 'method'>\n",
            "extract_init_dict is type <class 'method'>\n",
            "flip_sin_to_cos is type <class 'bool'>\n",
            "float is type <class 'method'>\n",
            "forward is type <class 'method'>\n",
            "freq_shift is type <class 'int'>\n",
            "from_config is type <class 'method'>\n",
            "from_pretrained is type <class 'method'>\n",
            "get_buffer is type <class 'method'>\n",
            "get_config_dict is type <class 'method'>\n",
            "get_extra_state is type <class 'method'>\n",
            "get_parameter is type <class 'method'>\n",
            "get_submodule is type <class 'method'>\n",
            "half is type <class 'method'>\n",
            "has_compatibles is type <class 'bool'>\n",
            "ignore_for_config is type <class 'list'>\n",
            "in_channels is type <class 'int'>\n",
            "ipu is type <class 'method'>\n",
            "is_gradient_checkpointing is type <class 'bool'>\n",
            "layers_per_block is type <class 'int'>\n",
            "load_attn_procs is type <class 'method'>\n",
            "load_config is type <class 'method'>\n",
            "load_state_dict is type <class 'method'>\n",
            "mid_block is type <class 'diffusers.models.unet_2d_blocks.UNetMidBlock2DCrossAttn'>\n",
            "mid_block_scale_factor is type <class 'int'>\n",
            "mid_block_type is type <class 'str'>\n",
            "modules is type <class 'method'>\n",
            "named_buffers is type <class 'method'>\n",
            "named_children is type <class 'method'>\n",
            "named_modules is type <class 'method'>\n",
            "named_parameters is type <class 'method'>\n",
            "norm_eps is type <class 'float'>\n",
            "norm_num_groups is type <class 'int'>\n",
            "num_class_embeds is type <class 'NoneType'>\n",
            "num_parameters is type <class 'method'>\n",
            "num_upsamplers is type <class 'int'>\n",
            "only_cross_attention is type <class 'bool'>\n",
            "out_channels is type <class 'int'>\n",
            "parameters is type <class 'method'>\n",
            "projection_class_embeddings_input_dim is type <class 'NoneType'>\n",
            "register_backward_hook is type <class 'method'>\n",
            "register_buffer is type <class 'method'>\n",
            "register_forward_hook is type <class 'method'>\n",
            "register_forward_pre_hook is type <class 'method'>\n",
            "register_full_backward_hook is type <class 'method'>\n",
            "register_load_state_dict_post_hook is type <class 'method'>\n",
            "register_module is type <class 'method'>\n",
            "register_parameter is type <class 'method'>\n",
            "register_to_config is type <class 'method'>\n",
            "requires_grad_ is type <class 'method'>\n",
            "resnet_time_scale_shift is type <class 'str'>\n",
            "sample_size is type <class 'NoneType'>\n",
            "save_attn_procs is type <class 'method'>\n",
            "save_config is type <class 'method'>\n",
            "save_pretrained is type <class 'method'>\n",
            "set_attention_slice is type <class 'method'>\n",
            "set_attn_processor is type <class 'method'>\n",
            "set_extra_state is type <class 'method'>\n",
            "set_use_memory_efficient_attention_xformers is type <class 'method'>\n",
            "share_memory is type <class 'method'>\n",
            "state_dict is type <class 'method'>\n",
            "time_cond_proj_dim is type <class 'NoneType'>\n",
            "time_embedding is type <class 'diffusers.models.embeddings.TimestepEmbedding'>\n",
            "time_embedding_type is type <class 'str'>\n",
            "time_proj is type <class 'diffusers.models.embeddings.Timesteps'>\n",
            "timestep_post_act is type <class 'NoneType'>\n",
            "to is type <class 'method'>\n",
            "to_empty is type <class 'method'>\n",
            "to_json_file is type <class 'method'>\n",
            "to_json_string is type <class 'method'>\n",
            "train is type <class 'method'>\n",
            "training is type <class 'bool'>\n",
            "type is type <class 'method'>\n",
            "up_block_types is type <class 'tuple'>\n",
            "up_blocks is type <class 'torch.nn.modules.container.ModuleList'>\n",
            "upcast_attention is type <class 'bool'>\n",
            "use_linear_projection is type <class 'bool'>\n",
            "xpu is type <class 'method'>\n",
            "zero_grad is type <class 'method'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the output of the last cell, you should see that the UNet class we are subclassing has a torch.nn.ModuleList called down_blocks, an module called mid_block, and another torch.nn.ModuleList called up_blocks. This should make sense considering you know what the general structure of a UNet is from Lab 4. Each of those blocks is one of the following types:\n",
        "\n",
        "*   CrossAttnDownBlock2D\n",
        "*   DownBlock2D\n",
        "*   CrossAttnUpBlock2D\n",
        "*   UpBlock2D\n",
        "*   UNetMidBlock2DCrossAttn\n",
        "\n",
        "To figure out the data type of a block, use `print(type(block))`. Once you know the data type of the block object, you can do ClassName??, and Colab will bring up a help window for it. Scroll down to see the function source code--this will help you understand how that block is used.\n",
        "\n",
        "You can also read the [stable diffusion paper](https://arxiv.org/abs/2112.10752) to figure out what is happening in this code.\n",
        "\n",
        "Add comments at the indicated locations in the code below:"
      ],
      "metadata": {
        "id": "WAKLvPx0U-2Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "At7j9ah_QIOE"
      },
      "outputs": [],
      "source": [
        "# DEFINE THE UNET\n",
        "\n",
        "from diffusers.models.unet_2d_condition import UNet2DConditionModel, UNet2DConditionOutput, Union\n",
        "\n",
        "class Lab9UNet2DConditionModel(UNet2DConditionModel):\n",
        "  def forward(\n",
        "      self,\n",
        "      sample: torch.FloatTensor,\n",
        "      timestep: Union[torch.Tensor, float, int],\n",
        "      encoder_hidden_states: torch.Tensor,\n",
        "      cross_attention_kwargs,\n",
        "    ) -> UNet2DConditionOutput:\n",
        "      \"\"\"\n",
        "      Args:\n",
        "        sample (`torch.FloatTensor`): (batch, channel, height, width) noisy inputs tensor\n",
        "        timestep (`torch.FloatTensor` or `float` or `int`): (batch) timesteps\n",
        "        encoder_hidden_states (`torch.FloatTensor`): (batch, channel, height, width) encoder hidden states (the text encoding in our case)\n",
        "\n",
        "      Returns:\n",
        "        [`~models.unet_2d_condition.UNet2DConditionOutput`]\n",
        "      \"\"\"\n",
        "      # Make sure sizes match up\n",
        "      # upsample size should be forwarded when sample is not a multiple of `default_overall_up_factor`\n",
        "      default_overall_up_factor = 2**self.num_upsamplers\n",
        "      forward_upsample_size = False\n",
        "      upsample_size = None\n",
        "      if any(s % default_overall_up_factor != 0 for s in sample.shape[-2:]):\n",
        "        forward_upsample_size = True\n",
        "\n",
        "      # 0. center input if necessary\n",
        "      if self.config.center_input_sample:\n",
        "        sample = 2 * sample - 1.0\n",
        "\n",
        "      # 1. time\n",
        "      timesteps = timestep\n",
        "      if not torch.is_tensor(timesteps):\n",
        "        timesteps = torch.tensor(\n",
        "          [timesteps], dtype=torch.long, device=sample.device\n",
        "        )\n",
        "      elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n",
        "        timesteps = timesteps[None].to(sample.device)\n",
        "\n",
        "      # broadcast to batch dimension and embed using provided projection and embedding for time\n",
        "      timesteps = timesteps.expand(sample.shape[0])\n",
        "      t_emb = self.time_proj(timesteps)\n",
        "      t_emb = t_emb.to(dtype=self.dtype)\n",
        "      emb = self.time_embedding(t_emb)\n",
        "\n",
        "      # 2. pre-process\n",
        "      sample = self.conv_in(sample)\n",
        "\n",
        "      # 3.\n",
        "      # Begin down sampling latent noise vector sample\n",
        "      down_block_res_samples = (sample,)\n",
        "      for downsample_block in self.down_blocks:\n",
        "        # If we come to an attention block in the UNet then \n",
        "        # incorpoate the text embedding into the computation\n",
        "        if (\n",
        "          hasattr(downsample_block, \"attentions\")\n",
        "          and downsample_block.attentions is not None\n",
        "        ):\n",
        "          sample, res_samples = downsample_block(\n",
        "            hidden_states=sample,\n",
        "            temb=emb,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "          )\n",
        "        # Otherwise continue to down sample as normal with sample\n",
        "        else:\n",
        "          sample, res_samples = downsample_block(hidden_states=sample, temb=emb)\n",
        "\n",
        "        # Add in the residual connection\n",
        "        down_block_res_samples += res_samples\n",
        "\n",
        "      # 4.\n",
        "      # Process sample through the middle of the UNet\n",
        "      sample = self.mid_block(\n",
        "        sample, emb, encoder_hidden_states=encoder_hidden_states\n",
        "      )\n",
        "\n",
        "      # 5.\n",
        "      # Begin up-sampling\n",
        "      for i, upsample_block in enumerate(self.up_blocks):\n",
        "        is_final_block = i == len(self.up_blocks) - 1\n",
        "\n",
        "        res_samples = down_block_res_samples[-len(upsample_block.resnets) :]\n",
        "        down_block_res_samples = down_block_res_samples[: -len(upsample_block.resnets)]\n",
        "\n",
        "        # if we have not reached the final block and need to forward the\n",
        "        # upsample size, we do it here\n",
        "        if not is_final_block and forward_upsample_size:\n",
        "          upsample_size = down_block_res_samples[-1].shape[2:]\n",
        "\n",
        "        # If we come to an attention block while up-sampling then incorporate\n",
        "        # the text embedding into the calculation\n",
        "        if (\n",
        "          hasattr(upsample_block, \"attentions\")\n",
        "          and upsample_block.attentions is not None\n",
        "        ):\n",
        "          sample = upsample_block(\n",
        "            hidden_states=sample,\n",
        "            temb=emb,\n",
        "            res_hidden_states_tuple=res_samples,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            upsample_size=upsample_size,\n",
        "          )\n",
        "        # Otherwise proceed as normal with the sample\n",
        "        else:\n",
        "          sample = upsample_block(\n",
        "            hidden_states=sample,\n",
        "            temb=emb,\n",
        "            res_hidden_states_tuple=res_samples,\n",
        "            upsample_size=upsample_size,\n",
        "          )\n",
        "          \n",
        "      # 6. post-process\n",
        "      sample = self.conv_norm_out(sample)\n",
        "      sample = self.conv_act(sample)\n",
        "      sample = self.conv_out(sample)\n",
        "\n",
        "      return UNet2DConditionOutput(sample=sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYkgGizTW3oB"
      },
      "source": [
        "### Part 2: The scheduler\n",
        "\n",
        "It is the job of a \"scheduler\" object to add noise to the image in a markovian process while training, and to subtract the UNet's noise prediction from the image (step 5 in the outline of the pipeline from part 1) during inference.\n",
        "\n",
        "The latest version of the stable diffusion pipeline by default uses a PNDM scheduler, but for we will use the DDIM scheduler as described in the original paper. This will still work well and will align better with what was discussed in lecture.\n",
        "\n",
        "We subclass the DDIM scheduler from the provided implementation to gain access to the functions that are not of interest to us, but you must override the indicated method with your implementation. The method you will implement is the step method, which intakes the model noise prediction, sample, timestep, and eta, and returns $x_{t-1}$.\n",
        "\n",
        "The benefit of the DDIM scheduler is that while Stable Diffusion was trained using many timesteps (say 1000) for the forward process, we can do inference with far fewer time steps (say 50). One thing you will have to figure out in this function is what the current timestep is, using the number of training timesteps vs the number of inference timesteps.  (Note that `timestep` and `prev_timestep` are in terms of *training* timesteps, even though in inference timesteps: `prev_timestep_inf = timestep_inf - 1`. You need will to convert between the two because the model was trained in training timesteps and can't correctly interpret inference timesteps without conversion.)\n",
        "\n",
        "*   [DDIM paper](https://arxiv.org/pdf/2010.02502.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7MS4Ph0YiNK_"
      },
      "outputs": [],
      "source": [
        "# DEFINE THE DDIM SCHEDULER\n",
        "\n",
        "from diffusers.schedulers import DDIMScheduler\n",
        "from diffusers.schedulers.scheduling_ddim import DDIMSchedulerOutput\n",
        "\n",
        "class Lab9DDIMScheduler(DDIMScheduler):\n",
        "  def step(\n",
        "        self,\n",
        "        model_output: torch.FloatTensor,\n",
        "        timestep: int,\n",
        "        sample: torch.FloatTensor,\n",
        "        eta: float = 0.0,\n",
        "  ) -> DDIMSchedulerOutput:\n",
        "    \"\"\"\n",
        "    Predict the sample at the previous timestep by reversing the SDE. Core function to propagate the diffusion\n",
        "    process from the learned model outputs (most often the predicted noise).\n",
        "\n",
        "    Args:\n",
        "        model_output (`torch.FloatTensor`): direct output from learned diffusion model.\n",
        "        timestep (`int`): current discrete timestep in the diffusion chain.\n",
        "        sample (`torch.FloatTensor`):\n",
        "            current instance of sample being created by diffusion process.\n",
        "        eta (`float`): weight of noise for added noise in diffusion step.\n",
        "\n",
        "    Returns:\n",
        "        [`~schedulers.scheduling_utils.DDIMSchedulerOutput`]\n",
        "    \"\"\"\n",
        "    # Implement formula (12) of DDIM paper https://arxiv.org/pdf/2010.02502.pdf\n",
        "    # Using formula(16) for sigma.\n",
        "    # Note that eq. (12) applies to a single reverse diffusion step, but in this\n",
        "    # function we apply it to a larger diffusion step t - delta_t\n",
        "    \n",
        "    # Notation used in this function: <variable name> -> <name in paper>\n",
        "    # - model_output -> e_theta(t)(x_t)\n",
        "    # - timestep -> t\n",
        "    # - sample -> x_t\n",
        "    # - eta -> eta (eq. 16)\n",
        "    # - pred_original_sample -> \"predicted x_0\" in eq. 12\n",
        "    # - prev_sample -> x_{t-1} in eq. 12\n",
        "\n",
        "    # Renaming some member variables to be more intuitive and line up with the paper\n",
        "    num_train_timesteps = self.config.num_train_timesteps # T\n",
        "    num_inference_steps = self.num_inference_steps # tau\n",
        "    alphas = self.alphas_cumprod\n",
        "\n",
        "    # 1. get previous step value (=t-1)\n",
        "    # Hint: You can derive the inference time step size (delta_t) from T and tau\n",
        "    delta_t = num_train_timesteps // num_inference_steps\n",
        "    prev_timestep = timestep - delta_t\n",
        "\n",
        "    # 2. get alpha_t and alpha_t - 1\n",
        "    alpha_t = alphas[timestep]\n",
        "\n",
        "    if prev_timestep < 0:\n",
        "      alpha_t_prev = torch.Tensor(1)\n",
        "    else:\n",
        "      alpha_t_prev = alphas[prev_timestep]\n",
        "\n",
        "    alpha_t, alpha_t_prev = alpha_t.to('cuda'), alpha_t_prev.to('cuda')\n",
        "\n",
        "    # 3. compute predicted original sample from predicted noise, also called\n",
        "    # \"predicted x_0\" of formula (12)\n",
        "    model_ouput, sample = model_output.to('cuda'), sample.to('cuda')\n",
        "    pred_original_sample = (sample - torch.sqrt(1 - alpha_t) * model_output) / torch.sqrt(alpha_t)\n",
        "\n",
        "    # 4. Clip pred_original_sample or \"predicted x_0\" between -1 and 1\n",
        "    if self.config.clip_sample:\n",
        "      pred_original_sample = torch.clamp(pred_original_sample, -1, 1)\n",
        "\n",
        "    # 5. compute variance: \"sigma_t(η)\" -> see formula (16)\n",
        "    # σ_t = eta * sqrt((1 − α_t−1)/(1 − α_t)) * sqrt(1 − α_t/α_t−1)\n",
        "    sigma_t = eta * torch.sqrt( (1 - alpha_t_prev) / (1 - alpha_t) ) * torch.sqrt(1 - alpha_t / alpha_t_prev)\n",
        "\n",
        "    # 6. compute \"direction pointing to x_t\" of formula (12)\n",
        "    pred_sample_direction = torch.sqrt(1 - alpha_t_prev - sigma_t **2) * model_output\n",
        "\n",
        "    # 7. compute x_t without \"random noise\" of formula (12)\n",
        "    prev_sample_wo_noise = torch.sqrt(alpha_t_prev) * pred_original_sample + pred_sample_direction\n",
        "\n",
        "    # 8. compute x_t with \"random noise\" added (last term of formula (12))\n",
        "    size_noise = prev_sample_wo_noise.size()\n",
        "    noise = sigma_t * torch.normal(mean=0.0, std=1.0, size=size_noise, device='cuda')\n",
        "    \n",
        "    prev_sample = prev_sample_wo_noise + noise\n",
        "\n",
        "    return DDIMSchedulerOutput(\n",
        "        prev_sample=prev_sample, pred_original_sample=pred_original_sample\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp4_qlklTQlw"
      },
      "source": [
        "### Part 3: Loading pretrained weights and setting up the pipeline\n",
        "\n",
        "Now, we begin putting the whole pipeline together. \n",
        "\n",
        "Other diffusion models like Imagen or DALL-E perform the denoising in pixel space; it was a key contribution of the Stable Diffusion authors to realize it could be done in latent space, significantly reducing the hardware required for Stable Diffusion. Even with this technique, we can't train SD in the memory Colab gives us, but we can at least run inference!\n",
        "\n",
        "You should load a pretrained VAE from huggingface; this shouldn't be too difficult as we give an example of loading weights from HF right above it. You should also answer the following questions:\n",
        "\n",
        "1.   Why does Stable Diffusion need a VAE?\n",
        "2.   What are the dimensions of the latent space of the VAE (i.e. when you encode an image using it)? What are the dimensions of the input image? By what factor is the memory footprint reduced in the latent space compared to pixel space? How does this relate to the performance advantage of Stable Diffusion over pixel-space diffusers like Imagen or DALL-E?\n",
        "\n",
        "Once you've succeeded in loading these weights, you will pass the UNet, scheduler, and VAE to the pipeline constructor. If you didn't care to override these models, it would instantiate them itself, but here, you should pass them in. **(This means you can test your implementation of one by only passing it in and letting the pipeline instantiate the others from defaults!)**\n",
        "\n",
        "For this step, write comments describing what is happening at the indicated parts of the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "a8cce75345b94687bd24a97451fe0638",
            "e706dbf718f04083be194d2eeb3f0323",
            "c7cac2e764334ce8a42a092ce4178786",
            "2c7b05867cc4494fa06c649e96c9c5d2",
            "7f99ac6c23d549138697b5f09a24e81f",
            "f69c504c8c24473f96daa773c1c7266f",
            "b806fd16ee424e35b65fb1adeafadd47",
            "a8b11ca856644888b13f37a0fddea081",
            "0ae05f5040644022a655c146130f863f",
            "d6dfcb6f910e48e18663000c8ceeae49",
            "95f3c901412e4f2191a06f37128d7cf2"
          ]
        },
        "id": "vPQgEt9PJa0J",
        "outputId": "9b1a5c41-d618-4f10-db33-7aa5a592d1c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8cce75345b94687bd24a97451fe0638"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
          ]
        }
      ],
      "source": [
        "# SET UP PIPELINE\n",
        "# This is where we condition the diffusion performed by the UNet using latent \n",
        "# text vectors from the language model. We then decode the output from the UNet\n",
        "# using the VAE with the text information.\n",
        "\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, AutoencoderKL\n",
        "\n",
        "# Instantiate user defined scheduler\n",
        "scheduler = Lab9DDIMScheduler(\n",
        "    beta_start=0.00085, # You can mess with these, but they work well\n",
        "    beta_end=0.012, \n",
        "    beta_schedule=\"scaled_linear\"\n",
        ")\n",
        "\n",
        "# Instantiate user defined UNet object for diffusion\n",
        "unet = Lab9UNet2DConditionModel.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\",\n",
        "    subfolder=\"unet\",\n",
        "    use_auth_token=True\n",
        ")\n",
        "\n",
        "# Instantiate autoencoder for text latent space\n",
        "vae = AutoencoderKL.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\", \n",
        "    subfolder=\"vae\", \n",
        "    use_auth_token=True\n",
        ")\n",
        "\n",
        "# Set up pipeline with UNet and VAE\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    \"CompVis/stable-diffusion-v1-4\",\n",
        "    unet=unet,\n",
        "    scheduler=scheduler,\n",
        "    vae=vae,\n",
        "    use_auth_token=True\n",
        ").to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S5VhQYCUZ8l"
      },
      "source": [
        "### Part 4: Inference\n",
        "\n",
        "Lastly, come up with a creative prompt (not just using the provided example prompts) and generate an image! If you have enough GPU RAM, you may be able to process several prompts at once. It could be interesting to compare the model's interpretation of several similar prompts, as in the given prompt list, or to add descriptors like \"long exposure\", \"35 mm\", or \"photorealistic\" and see what that changes. \n",
        "\n",
        "It could also be interesting to test the limit of the model's understanding of the prompt; if you say, \"A blue \\<something\\> and a red \\<something\\>\", does it ever mix them up? What are the failure modes of this model?\n",
        "\n",
        "Stable Diffusion was trained using 1000 training timesteps. Using a DDIM scheduler allows us to sample using far fewer. Generate images with various numbers of inference steps (controlled by tau). What values of tau seem to offer the best quality/inference time tradeoff?\n",
        "\n",
        "Note: If you get a blank image that was identified as \"NSFW\", it probably is due to the generated image being pure static that can't be identified, and is labeled NSFW just to be safe. This is probably due to an error in the way you implemented the DDIM scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iuA8R8lDJecr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "64578464ce9245c896ab087485d982e9",
            "f84556c2709f44db81cd3e46323c5e7f",
            "b7797f600af541e1bee8dfe84cb6ee9a",
            "8cbfb096f4dd4c029ff797a574237dc7",
            "4cc6aad2906149b6b5fc1d6ac2f746ad",
            "58a54df1d6b14f32b9fc7e7f781607f3",
            "e3fa3346bf3e4d1ab4cbfca882d6a756",
            "421a202ba630450e84ffcdd1a04d25fc",
            "e54bdc5ba19e48189d18156010f22a3c",
            "79ef1018e6274bf69da30006b6544b2b",
            "761cb0a9cd134c60b0719e3118d84f96"
          ]
        },
        "outputId": "a3634d67-6718-4a5d-9b62-f1a0e2e142eb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64578464ce9245c896ab087485d982e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.026121728\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StableDiffusionPipelineOutput(images=[<PIL.Image.Image image mode=RGB size=512x512 at 0x7FD1176FF880>], nsfw_content_detected=[True])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# INFERENCE\n",
        "\n",
        "tau = 100\n",
        "prompt = [\n",
        "    \"a mouse poking its head out of the center of the Moon which looks like a giant cheese wheel\",\n",
        "    \"a watercolor of an enchanted forest\",\n",
        "    \"a watercolor of a mystical forest\"\n",
        "]\n",
        "  \n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "  pipeline_result = pipe(prompt, num_inference_steps=tau) \n",
        "                                 # This would be the place to pass in other \n",
        "                                 # parameters as desired and as accepted by the function, \n",
        "                                 # like the desired height and width, or the guidance scale\n",
        "                                 # (though we didn't talk about guidance in this lab).\n",
        "\n",
        "print(torch.cuda.max_memory_allocated()/1e9)\n",
        "pipeline_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "j0z6Vy_7NZi6",
        "outputId": "f5f915cb-3359-436b-9ab6-43b11b79dae9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=512x512 at 0x7FD11597BEB0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIACAIAAAB7GkOtAAADEUlEQVR4nO3BgQAAAADDoPlTX+EAVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBvArQAAVkUTe8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# DISPLAY IMAGES\n",
        "\n",
        "for img in pipeline_result[\"images\"]:\n",
        "  display(img)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d1bd8c25c604e649acb52b5f08677b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ee4cb866125490aaad3aa640e055ef1",
              "IPY_MODEL_1dc4d0f83c354194aca66149aa09d919",
              "IPY_MODEL_53798a1f893248aa8885ca4dcca84ed0",
              "IPY_MODEL_be19c716c95b4ec196d8455277cc5159",
              "IPY_MODEL_6e6f1f36ad9b4ebfbc377a8e647caa30"
            ],
            "layout": "IPY_MODEL_7f7d402e559b4510a1c6afcd4feb8fbd"
          }
        },
        "4ee4cb866125490aaad3aa640e055ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8738df5db90b4a438a8467309b8f2189",
            "placeholder": "​",
            "style": "IPY_MODEL_fd7f395c1e224e9480542f1f41b3c6ec",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "1dc4d0f83c354194aca66149aa09d919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c220a2a670684b328c832836702dead0",
            "placeholder": "​",
            "style": "IPY_MODEL_08c1aae8f6b04204b8b5b62f719c395f",
            "value": ""
          }
        },
        "53798a1f893248aa8885ca4dcca84ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_7c5bbd2b9b8f4e8f9d02bbb1215142b5",
            "style": "IPY_MODEL_1d5afcaa50fe485a8663d00078233e6f",
            "value": true
          }
        },
        "be19c716c95b4ec196d8455277cc5159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f4c0475974d04c2aaa6d29ad255aacf5",
            "style": "IPY_MODEL_01d0173897364af2ad3b7594fe304933",
            "tooltip": ""
          }
        },
        "6e6f1f36ad9b4ebfbc377a8e647caa30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5047288108524606abbf9418d7820a99",
            "placeholder": "​",
            "style": "IPY_MODEL_ee1e0d9187c34a8eab8cfc0c68d1b05c",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "7f7d402e559b4510a1c6afcd4feb8fbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "8738df5db90b4a438a8467309b8f2189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd7f395c1e224e9480542f1f41b3c6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c220a2a670684b328c832836702dead0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c1aae8f6b04204b8b5b62f719c395f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c5bbd2b9b8f4e8f9d02bbb1215142b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5afcaa50fe485a8663d00078233e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4c0475974d04c2aaa6d29ad255aacf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d0173897364af2ad3b7594fe304933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5047288108524606abbf9418d7820a99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1e0d9187c34a8eab8cfc0c68d1b05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8cce75345b94687bd24a97451fe0638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e706dbf718f04083be194d2eeb3f0323",
              "IPY_MODEL_c7cac2e764334ce8a42a092ce4178786",
              "IPY_MODEL_2c7b05867cc4494fa06c649e96c9c5d2"
            ],
            "layout": "IPY_MODEL_7f99ac6c23d549138697b5f09a24e81f"
          }
        },
        "e706dbf718f04083be194d2eeb3f0323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f69c504c8c24473f96daa773c1c7266f",
            "placeholder": "​",
            "style": "IPY_MODEL_b806fd16ee424e35b65fb1adeafadd47",
            "value": "Fetching 16 files: 100%"
          }
        },
        "c7cac2e764334ce8a42a092ce4178786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8b11ca856644888b13f37a0fddea081",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ae05f5040644022a655c146130f863f",
            "value": 16
          }
        },
        "2c7b05867cc4494fa06c649e96c9c5d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6dfcb6f910e48e18663000c8ceeae49",
            "placeholder": "​",
            "style": "IPY_MODEL_95f3c901412e4f2191a06f37128d7cf2",
            "value": " 16/16 [00:00&lt;00:00, 1379.34it/s]"
          }
        },
        "7f99ac6c23d549138697b5f09a24e81f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f69c504c8c24473f96daa773c1c7266f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b806fd16ee424e35b65fb1adeafadd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8b11ca856644888b13f37a0fddea081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae05f5040644022a655c146130f863f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6dfcb6f910e48e18663000c8ceeae49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95f3c901412e4f2191a06f37128d7cf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64578464ce9245c896ab087485d982e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f84556c2709f44db81cd3e46323c5e7f",
              "IPY_MODEL_b7797f600af541e1bee8dfe84cb6ee9a",
              "IPY_MODEL_8cbfb096f4dd4c029ff797a574237dc7"
            ],
            "layout": "IPY_MODEL_4cc6aad2906149b6b5fc1d6ac2f746ad"
          }
        },
        "f84556c2709f44db81cd3e46323c5e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a54df1d6b14f32b9fc7e7f781607f3",
            "placeholder": "​",
            "style": "IPY_MODEL_e3fa3346bf3e4d1ab4cbfca882d6a756",
            "value": "100%"
          }
        },
        "b7797f600af541e1bee8dfe84cb6ee9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_421a202ba630450e84ffcdd1a04d25fc",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e54bdc5ba19e48189d18156010f22a3c",
            "value": 100
          }
        },
        "8cbfb096f4dd4c029ff797a574237dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79ef1018e6274bf69da30006b6544b2b",
            "placeholder": "​",
            "style": "IPY_MODEL_761cb0a9cd134c60b0719e3118d84f96",
            "value": " 100/100 [00:06&lt;00:00, 15.41it/s]"
          }
        },
        "4cc6aad2906149b6b5fc1d6ac2f746ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a54df1d6b14f32b9fc7e7f781607f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3fa3346bf3e4d1ab4cbfca882d6a756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "421a202ba630450e84ffcdd1a04d25fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e54bdc5ba19e48189d18156010f22a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79ef1018e6274bf69da30006b6544b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "761cb0a9cd134c60b0719e3118d84f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}