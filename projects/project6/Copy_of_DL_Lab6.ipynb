{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ6umMb3WZFm"
      },
      "source": [
        "<a \n",
        "href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab6.ipynb\"\n",
        "  target=\"_parent\">\n",
        "  <img\n",
        "    src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
        "    alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cksgAH12XRjV"
      },
      "source": [
        "# Lab 6: Sequence-to-sequence models\n",
        "\n",
        "### Description:\n",
        "For this lab, you will code up the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original.\n",
        "\n",
        "This lab will help you develop several new skills, as well as understand some best practices needed for building large models. In addition, we'll be able to create networks that generate neat text!\n",
        "\n",
        "### Deliverable:\n",
        "- Fill in the code for the RNN (using PyTorch's built-in GRU).\n",
        "- Fill in the training loop\n",
        "- Fill in the evaluation loop. In this loop, rather than using a validation set, you will sample text from the RNN.\n",
        "- Implement your own GRU cell.\n",
        "- Train your RNN on a new domain of text (Star Wars, political speeches, etc. - have fun!)\n",
        "\n",
        "### Grading Standards:\n",
        "- 20% Implementation the RNN\n",
        "- 20% Implementation training loop\n",
        "- 20% Implementation of evaluation loop\n",
        "- 20% Implementation of your own GRU cell\n",
        "- 20% Training of your RNN on a domain of your choice\n",
        "\n",
        "### Tips:\n",
        "- Read through all the helper functions, run them, and make sure you understand what they are doing\n",
        "- At each stage, ask yourself: What should the dimensions of this tensor be? Should its data type be float or int? (int is called `long` in PyTorch)\n",
        "- Don't apply a softmax inside the RNN if you are using an nn.CrossEntropyLoss (this module already applies a softmax to its input).\n",
        "\n",
        "### Example Output:\n",
        "An example of my final samples are shown below (more detail in the\n",
        "final section of this writeup), after 150 passes through the data.\n",
        "Please generate about 15 samples for each dataset.\n",
        "\n",
        "<code>\n",
        "And ifte thin forgision forward thene over up to a fear not your\n",
        "And freitions, which is great God. Behold these are the loss sub\n",
        "And ache with the Lord hath bloes, which was done to the holy Gr\n",
        "And appeicis arm vinimonahites strong in name, to doth piseling \n",
        "And miniquithers these words, he commanded order not; neither sa\n",
        "And min for many would happine even to the earth, to said unto m\n",
        "And mie first be traditions? Behold, you, because it was a sound\n",
        "And from tike ended the Lamanites had administered, and I say bi\n",
        "</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2i_QpSsWG4c"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 0: Readings, data loading, and high level training\n",
        "\n",
        "---\n",
        "\n",
        "There is a tutorial here that will help build out scaffolding code, and get an understanding of using sequences in pytorch.\n",
        "\n",
        "* Read the following\n",
        "\n",
        "> * [Pytorch sequence-to-sequence tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) (You will be implementing the decoder, not the encoder, as we are not doing sequence-to-sequence translation.)\n",
        "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "l7bdZWxvJrsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1781f10c-92be-427c-cea1-57216c72b987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-18 22:53:30--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 18.235.185.127, 52.205.194.150, 18.215.222.38, ...\n",
            "Connecting to piazza.com (piazza.com)|18.235.185.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2023-02-18 22:53:31--  https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving cdn-uploads.piazza.com (cdn-uploads.piazza.com)... 108.156.60.45, 108.156.60.68, 108.156.60.61, ...\n",
            "Connecting to cdn-uploads.piazza.com (cdn-uploads.piazza.com)|108.156.60.45|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "./text_files.tar.gz 100%[===================>]   1.46M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-02-18 22:53:31 (56.8 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.8/dist-packages (1.3.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        " \n",
        "import pdb\n",
        "\n",
        "import pandas as pd\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "\n",
        "file = unidecode.unidecode(open('./text_files/lotr.txt').read())\n",
        "\n",
        "file_len = len(file)\n",
        "\n",
        "my_file = pd.read_csv('./text_files/avatar.csv', encoding='latin1')\n",
        "my_file = my_file.loc[:, 'character_words']\n",
        "\n",
        "my_file_text = str()\n",
        "for i in range(len(my_file)):\n",
        "  datum = my_file[i]\n",
        "\n",
        "  if datum != 'NA' and type(datum) is not float:\n",
        "    for c in datum:\n",
        "      if c in all_characters:\n",
        "        my_file_text += c\n",
        "    \n",
        "    my_file_text += '\\n'\n",
        "\n",
        "my_file_len = len(my_file_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TxBeKeNjJ0NQ"
      },
      "outputs": [],
      "source": [
        "def random_chunk(fl, fl_len, chunk_len):\n",
        "  start_index = random.randint(0, fl_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "   \n",
        "  return fl[start_index:end_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "On0_WitWJ99e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "    tensor[c] = all_characters.index(string[c])\n",
        "  \n",
        "  return tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJPTLcaYmfI"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Creating your own GRU cell \n",
        "\n",
        "**(Come back to this later - its defined here so that the GRU will be defined before it is used)**\n",
        "\n",
        "---\n",
        "\n",
        "The cell that you used in Part 1 was a pre-defined Pytorch layer. Now, write your own GRU class using the same parameters as the built-in Pytorch class does.\n",
        "\n",
        "Please do not look at the documentation's code for the GRU cell definition. The answer is right there in the code, and in theory, you could just cut-and-paste it. This bit is on your honor!\n",
        "\n",
        "**TODO:**\n",
        "* Create a custom GRU cell\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "aavAv50ZKQ-F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(GRU, self).__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.tanh = nn.Tanh()\n",
        "\n",
        "    self.mods = nn.ModuleDict() # nn.ModuleList()\n",
        "    for i in range(1, num_layers + 1):\n",
        "      module_ir = nn.Linear(input_size, hidden_size, bias=True)\n",
        "      module_hr = nn.Linear(hidden_size, hidden_size, bias=True)\n",
        "      module_iz = nn.Linear(input_size, hidden_size, bias=True)\n",
        "      module_hz = nn.Linear(hidden_size, hidden_size, bias=True)\n",
        "      module_in = nn.Linear(input_size, hidden_size, bias=True)\n",
        "      module_hn = nn.Linear(hidden_size, hidden_size, bias=True)\n",
        "      \n",
        "      self.mods['ir:' + str(i)] = module_ir\n",
        "      self.mods['hr:' + str(i)] = module_hr\n",
        "      self.mods['iz:' + str(i)] = module_iz\n",
        "      self.mods['hz:' + str(i)] = module_hz\n",
        "      self.mods['in:' + str(i)] = module_in\n",
        "      self.mods['hn:' + str(i)] = module_hn\n",
        "\n",
        "  def forward(self, inputs, hidden):\n",
        "    # Each layer does the following:\n",
        "    hiddens = []\n",
        "    for i in range(1, self.num_layers + 1):\n",
        "      r_t = self.sigmoid(self.mods['ir:' + str(i)](inputs) + self.mods['hr:' + str(i)](hidden[i - 1])) # num_layer x 1 x hidden_size\n",
        "      z_t = self.sigmoid(self.mods['iz:' + str(i)](inputs) + self.mods['hz:' + str(i)](hidden[i - 1]))\n",
        "      n_t = self.tanh(self.mods['in:' + str(i)](inputs) + torch.mul(r_t, self.mods['hn:' + str(i)](hidden[i - 1])))\n",
        "\n",
        "      inputs = torch.mul( torch.ones_like(z_t) - z_t, n_t) + torch.mul(z_t, hidden[i - 1])\n",
        "      \n",
        "      hiddens.append(hidden[i - 1])\n",
        "    \n",
        "    hiddens = torch.stack(hiddens)\n",
        "    outputs = inputs\n",
        "\n",
        "    return outputs, hiddens\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtXdX-B_WiAY"
      },
      "source": [
        "---\n",
        "\n",
        "##  Part 1: Building a sequence to sequence model\n",
        "\n",
        "---\n",
        "\n",
        "Great! We have the data in a useable form. We can switch out which text file we are reading from, and trying to simulate.\n",
        "\n",
        "We now want to build out an RNN model, in this section, we will use all built in Pytorch pieces when building our RNN class.\n",
        "\n",
        "\n",
        "**TODO:**\n",
        "* Create an RNN class that extends from nn.Module.\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d6tNdEnzWj5F"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, n_layers=1, my_GRU=False):\n",
        "    super(RNN, self).__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    \n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "    if not my_GRU:\n",
        "      self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "    else:\n",
        "      self.gru = GRU(hidden_size, hidden_size, n_layers) # user defined GRU\n",
        "    \n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input_char, hidden):\n",
        "    # by reviewing the documentation, construct a forward function that properly\n",
        "    # uses the output of the GRU\n",
        "\n",
        "    output = self.embedding(input_char).view(1, 1, -1)\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    out_decoded = self.out(output)\n",
        "    \n",
        "    return out_decoded, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.n_layers, 1, self.hidden_size, device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hrhXghEPKD-5"
      },
      "outputs": [],
      "source": [
        "def random_training_set(fl, fl_len, chunk_len):    \n",
        "  chunk = random_chunk(fl, fl_len, chunk_len)\n",
        "  inp = char_tensor(chunk[:-1])\n",
        "  target = char_tensor(chunk[1:])\n",
        "  \n",
        "  return inp, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpiGObbBX0Mr"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "We now want to be able to train our network, and sample text after training.\n",
        "\n",
        "This function outlines how training a sequence style network goes. \n",
        "\n",
        "**TODO:**\n",
        "* Fill in the pieces.\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2ALC3Pf8Kbsi"
      },
      "outputs": [],
      "source": [
        "# NOTE: decoder_optimizer, decoder, and criterion will be defined below as global variables\n",
        "def train(inp, target, decoder, optimizer):\n",
        "  hidden = decoder.init_hidden()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  target_length = target.size(0)\n",
        "\n",
        "  loss = 0\n",
        "  \n",
        "  for di in range(target_length):\n",
        "    output, hidden = decoder(inp[di], hidden)\n",
        "    \n",
        "    loss += criterion(torch.squeeze(output, 0), torch.unsqueeze(target[di], 0)) \n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN06NUu3YRlz"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "You can at this time, if you choose, also write out your train loop boilerplate that samples random sequences and trains your RNN. This will be helpful to have working before writing your own GRU class.\n",
        "\n",
        "If you are finished training, or during training, and you want to sample from the network you may consider using the following function. If your RNN model is instantiated as `decoder`then this will probabilistically sample a sequence of length `predict_len`\n",
        "\n",
        "**TODO:**\n",
        "* Fill out the evaluate function to generate text frome a primed string\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "B-bp-OZ1KjNh"
      },
      "outputs": [],
      "source": [
        "def sample_outputs(output, temperature):\n",
        "    \"\"\"Takes in a vector of unnormalized probability weights and samples a character from the distribution\"\"\"\n",
        "    # As temperature approaches 0, this sampling function becomes argmax (no randomness)\n",
        "    # As temperature approaches infinity, this sampling function becomes a purely random choice\n",
        "    return torch.multinomial(torch.exp(output / temperature), 1)\n",
        "\n",
        "def evaluate(decoder, prime_str='A', predict_len=100, temperature=0.8): # produce new sentence\n",
        "  ## initialize hidden state, initialize other useful variables\n",
        "  hidden = decoder.init_hidden()\n",
        "  output_str = str(prime_str)\n",
        "  prime_char_tensor = char_tensor(output_str)\n",
        "\n",
        "  _, hidden = decoder(prime_char_tensor[0], hidden)\n",
        "\n",
        "  while len(output_str) <= predict_len:\n",
        "    input_char_tensor = char_tensor(output_str)\n",
        "    output, hidden = decoder(input_char_tensor[-1], hidden) # dist of characters\n",
        "    \n",
        "    index = sample_outputs(torch.squeeze(output, 0), temperature) # index of likely char\n",
        "    char = all_characters[index]\n",
        "\n",
        "    output_str += char # buid output string\n",
        "  \n",
        "  return output_str\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du4AGA8PcFEW"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: (Create a GRU cell, requirements above)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFS2bpHSZEU6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Part 5: Run it and generate some text!\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**TODO:** \n",
        "* Create some cool output\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Assuming everything has gone well, you should be able to run the main function in the scaffold code, using either your custom GRU cell or the built in layer, and see output something like this. I trained on the “lotr.txt” dataset, using chunk_length=200, hidden_size=100 for 2000 epochs. These are the results, along with the prime string:\n",
        "\n",
        "---\n",
        "\n",
        " G:\n",
        " \n",
        " Gandalf was decrond. \n",
        "'All have lord you. Forward the road at least walk this is stuff, and \n",
        "went to the long grey housel-winding and kindled side was a sleep pleasuring, I do long \n",
        "row hrough. In  \n",
        "\n",
        " lo:\n",
        " \n",
        " lost death it. \n",
        "'The last of the gatherings and take you,' said Aragorn, shining out of the Gate. \n",
        "'Yes, as you there were remembaused to seen their pass, when? What \n",
        "said here, such seven an the sear \n",
        "\n",
        " lo:\n",
        " \n",
        " low, and frod to keepn \n",
        "Came of their most. But here priced doubtless to an Sam up is \n",
        "masters; he left hor as they are looked. And he could now the long to stout in the right fro horseless of \n",
        "the like \n",
        "\n",
        " I:\n",
        " \n",
        " I had been the \n",
        "in his eyes with the perushed to lest, if then only the ring and the legended \n",
        "of the less of the long they which as the \n",
        "enders of Orcovered and smood, and the p \n",
        "\n",
        " I:\n",
        " \n",
        " I they were not the lord of the hoomes. \n",
        "Home already well from the Elves. And he sat strength, and we \n",
        "housed out of the good of the days to the mountains from his perith. \n",
        "\n",
        "'Yess! Where though as if  \n",
        "\n",
        " Th:\n",
        " \n",
        " There yarden \n",
        "you would guard the hoor might. Far and then may was \n",
        "croties, too began to see the drumbred many line \n",
        "and was then hoard walk and they heart, and the chair of the \n",
        "Ents of way, might was \n",
        "\n",
        " G:\n",
        " \n",
        " Gandalf \n",
        "been lat of less the round of the stump; both and seemed to the trees and perished they \n",
        "lay are speered the less; and the wind the steep and have to she \n",
        "precious. There was in the oonly went \n",
        "\n",
        " wh:\n",
        " \n",
        " which went out of the door. \n",
        "Hull the King and of the The days of his brodo \n",
        "stumbler of the windard was a thing there, then it been shining langing \n",
        "to him poor land. They hands; though they seemed ou \n",
        "\n",
        " ra:\n",
        " \n",
        " rather,' have all the least deather \n",
        "down of the truven beginning to the house of sunk. \n",
        "'Nark shorts of the Eyes of the Gate your great nothing as Eret. \n",
        "'I wander trust horn, and there were not, it  \n",
        "\n",
        " I:\n",
        " \n",
        " I can have no mind \n",
        "together! Where don't may had one may little blung \n",
        "terrible to tales. And turn and Gandalf shall be not to as only the Cattring \n",
        "not stopped great the out them forms. On they she lo \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-nXFeCmdKodw"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "print_every = 50\n",
        "plot_every = 10\n",
        "hidden_size = 200\n",
        "n_layers = 3\n",
        "lr = 0.001\n",
        " \n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers, my_GRU=True) # user defined GRU\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKfozqw-6eqb",
        "outputId": "f0a64145-a6fc-4397-c8c3-90221579c3c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[29. (50 2%) 3.0866]\n",
            "Wh uD e hlgmadno  tteklahe gt aywsesea yceenitar tshhi gei  v  .'a lre tafgntaelbeewh\n",
            "baorseon\n",
            " h ind \n",
            "\n",
            "[57. (100 5%) 2.8205]\n",
            "Whe iusan teor nsare t pcirshos :oy t thi w s at \n",
            "hen I as nndr ly s fhhn, be \n",
            "hey aree, as thr w tew \n",
            "\n",
            "[85. (150 7%) 2.6988]\n",
            "Whe \n",
            "t Ed aud mere \n",
            ")de winre th ns \n",
            "puon t win ciut lhant \n",
            "tse s 're t.han we pthe anr \n",
            "the a om s y \n",
            "\n",
            "[112 (200 10%) 2.5405]\n",
            "Wheseda hee idos w se \n",
            "ther poonive uloninde theded or Go rsweg,r t and aoy \n",
            "\n",
            "d theme se nvhee fe \n",
            "\n",
            "a \n",
            "\n",
            "[140 (250 12%) 2.4567]\n",
            "Wher he or Ze at s l s and \n",
            "\n",
            "\n",
            "aomer oran s te \n",
            "qed sand \n",
            "f \n",
            "wer nts ad tofo af atore g. aves t \n",
            "ts se \n",
            "\n",
            "[168 (300 15%) 2.4062]\n",
            "Whe 'rkeong he as \n",
            "be fee cesanee nd mes sofon h fe \n",
            "Bkerasond touneasare wen as t t r. weorernd ward \n",
            "\n",
            "[197 (350 17%) 2.4806]\n",
            "Whyitoredas anan \n",
            "'la. \n",
            "wre ano st warer t te \n",
            "s on t hefr sastokowin, n wirady l k I Lhe ise thill \n",
            " \n",
            "\n",
            "[224 (400 20%) 2.3364]\n",
            "Whe s, Leing  to \n",
            "\n",
            "thesoutourn ame se d S\n",
            "n win antheshere he ware nstheld \n",
            "\n",
            "aing sthe s gathes, Hed  \n",
            "\n",
            "[252 (450 22%) 2.4768]\n",
            "Whe, cowe Shere mebe ' \n",
            "gibuowe at f lod carerindo \n",
            "the ouny the gheathe I ane f The t \n",
            "tthe the os \n",
            " \n",
            "\n",
            "[280 (500 25%) 2.3203]\n",
            "Whalat intoow. fay kdthavaeline areer 'zey aly te s \n",
            "\n",
            "wowonama ar aboud theverevef t n I \n",
            "\n",
            "chandear h \n",
            "\n",
            "[308 (550 27%) 2.5897]\n",
            "Wher beyonothed hithe Gad Ther ite, il tkont, \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Pid \n",
            "' \n",
            "\n",
            "'sg shese. wen we sang ms of, t, therouls \n",
            "\n",
            "[336 (600 30%) 2.3699]\n",
            "Whinghe \n",
            "Have luw owilowon s tay houlyrin t be as moflof s whey tho f an corofthe si angobure Che t m \n",
            "\n",
            "[364 (650 32%) 2.3973]\n",
            "Whared seoorko nurtheded ereround bchituthe f thad. outosthrind heas feand ily cald thede the ond d m \n",
            "\n",
            "[392 (700 35%) 2.4237]\n",
            "Whemouthedsas, t tedlpa m. umers d \n",
            "nd serere s arit ly, osind ae t'Nuy sast thald, d aimllld chey am \n",
            "\n",
            "[420 (750 37%) 2.3340]\n",
            "Whe he \n",
            "\n",
            "m wing f tthes Southe med \n",
            "be stheldore, ad r y yises hes, thes \n",
            "t t wouthigey, \n",
            "\n",
            "The oorin  \n",
            "\n",
            "[448 (800 40%) 2.4543]\n",
            "Whe p tof blon arn thare bus weand s tomon he hor t th he pt thin e \n",
            "\n",
            "\n",
            "\n",
            "wan areg \n",
            "' sans hobul arid m \n",
            "\n",
            "[476 (850 42%) 2.5831]\n",
            "Wht ra m hes he \n",
            "e \n",
            "\n",
            "rofele. murend t k ceg ice, seAr te. tr rtore cale or shelorer of an hofondono h \n",
            "\n",
            "[505 (900 45%) 2.3949]\n",
            "Wh \n",
            "\n",
            "\n",
            "\n",
            "thad obeaug, \n",
            "\n",
            "\n",
            "\n",
            "ck ie achele \n",
            "' He y \n",
            "f arend ud. afokirsthit wepe \n",
            "whan' cand o gorey ofhen  \n",
            "\n",
            "[532 (950 47%) 2.5115]\n",
            "Whe hen Bugaigher \n",
            "\n",
            "thengary an \n",
            "Thathaslore t \n",
            "\n",
            "\n",
            "I a th fo \n",
            "ithe ts hink whene \n",
            "tisend outhangofre b \n",
            "\n",
            "[561 (1000 50%) 2.6619]\n",
            "Whis ghee tsernd \n",
            "\n",
            "' seirenee hesam, therelo lensto mlf pare Sar hack acoreeshe be h whithe llird \n",
            "'  \n",
            "\n",
            "[589 (1050 52%) 2.6393]\n",
            "Whevel the Frice uth fofave at s orimorn weng. fely \n",
            "t le t wed thacaidon challongllllltoner I ulawes \n",
            "\n",
            "[617 (1100 55%) 2.4839]\n",
            "Whe o me h geve olnis s sons har tharere \n",
            "d \n",
            "\n",
            "\n",
            "s, anfishind. he ande rsem e g than he ar, te forire f \n",
            "\n",
            "[645 (1150 57%) 2.3905]\n",
            "Whan bouthens an \n",
            "\n",
            "\n",
            "the, ten tht re aten s r lt he a woroord fr sathind t andendy. at th s are \n",
            "croto \n",
            "\n",
            "[674 (1200 60%) 2.5069]\n",
            "Wherory thily we ilinthe apat.'Thopinouthechan wasthe whe itld \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "y blbugy therinde Bur awe tort. \n",
            "\n",
            "[701 (1250 62%) 2.4269]\n",
            "Whanout t d t tond thende oout ilf he o Ele. o thimind ' mes ot Dou m \n",
            "o we ad. wer \n",
            "ring oma \n",
            "ang at \n",
            "\n",
            "[730 (1300 65%) 2.4545]\n",
            "Whinghet w hend d a the h winf I s ith. this bofth a be haike, terang harers ther- s ly gang un w \n",
            "\n",
            "h \n",
            "\n",
            "[757 (1350 67%) 2.4663]\n",
            "Whe nd t an r half. and ate thed \n",
            "' his ayo to, at and \n",
            "Ras t erid, y aghe asored mendoun \n",
            "\n",
            "Are. arde \n",
            "\n",
            "[785 (1400 70%) 2.3777]\n",
            "Whecad the say t thtre Th. a h \n",
            "\n",
            "' I t ar illled t andey are and \n",
            "thed in Bor bbe d kn Itsthe han den \n",
            "\n",
            "[813 (1450 72%) 2.4518]\n",
            "Wht t n thasomongodspathendand ande g igouthis he me or the n t. he gr tritowaner! s p sse ling-ut \n",
            "\n",
            " \n",
            "\n",
            "[841 (1500 75%) 2.4532]\n",
            "Whire se sey cerdereve the l luleparonea athe I ded rd war ound \n",
            "'0e thind ftoleag thaliseas brs Gis  \n",
            "\n",
            "[869 (1550 77%) 2.4549]\n",
            "Whe \n",
            "\n",
            "ame the cle himat anngor. by helllinome tis s akeamet l fe t f f henicoremengarasemin arim thed \n",
            "\n",
            "[897 (1600 80%) 2.4633]\n",
            "Whed d Thearend \n",
            "\n",
            "od d teasr' wacoun d \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "So te wand'Wem aned stho ancend g thelot indoundenthe \n",
            "h \n",
            "\n",
            "[925 (1650 82%) 2.4324]\n",
            "Wharit in, \n",
            "\n",
            "gan f themut thofs mos, than. oucouler lo wry \n",
            "trsseazere om.'tr wengod avangstl he want \n",
            "\n",
            "[952 (1700 85%) 2.3410]\n",
            "Whe of s angashain stomecose trund de ce wis pen mun ane oway s tse d ofe t o y se abe thacongeng fof \n",
            "\n",
            "[980 (1750 87%) 2.4100]\n",
            "Whis atatere adous he histsanglsere hit tot il taga ' hid: Fo Hed p de torora mindomed holdady Noutor \n",
            "\n",
            "[100 (1800 90%) 2.3721]\n",
            "Whe athire ' are \n",
            "as. be busthainene realar ig bes wereat wer theeris oole s t momilethan ouren \n",
            "Thed \n",
            "\n",
            "[103 (1850 92%) 2.3650]\n",
            "Whanded And in ay, fot in hed d ththen I cand thigandy aked lfofulisulat the t \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fantll memithe de \n",
            "\n",
            "[106 (1900 95%) 2.4679]\n",
            "Whe ope \n",
            "Busangl ofo wang strend tod idesthild oshe herstoreran ngise \n",
            "orr e \n",
            "ang t wonen the wat the \n",
            "\n",
            "[109 (1950 97%) 2.4163]\n",
            "Whecancokyo s s her of astromofthorclle banofrethewan wand (r aroulyisthe athan \n",
            "Nod, \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The as ns  \n",
            "\n",
            "[111 (2000 100%) 2.4328]\n",
            "Whe che lames y obe o t be fush htheey arey and t wadowarns \n",
            "\n",
            "land s ang oran whorom:; s \n",
            "\n",
            "Ba t re bu \n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_epochs = 2000\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  loss_ = train(*random_training_set(file, file_len, 200), decoder, decoder_optimizer)\n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "      print('[%.3s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "      print(evaluate(decoder, 'Wh', 100), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(loss_avg / plot_every)\n",
        "      loss_avg = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(all_losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "33Kn6P4v9CY7",
        "outputId": "ddae14a7-75fa-4cd7-a9af-354f9c3e5f25"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee0so6aKJ5L8",
        "outputId": "bc7bb629-f23c-402e-9bcd-6725a90caffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " he\n",
            " hee ring tt s tous wadst s han bofend ond or thawoo \n",
            "\n",
            "\n",
            "m t \n",
            "\n",
            "y \n",
            "\n",
            "Bund, ieljume st se Bolo o sly ' at is thanathers. ' as t Ithe I hin th th \n",
            "y \n",
            "hat d t ot s y mase tw ind. e t \n",
            "\n",
            "un hitpl thirardoud le \n",
            "\n",
            " Th\n",
            " Thourtest they igot sus sthay t bere Fr. noton t f tund h on was ged he wer s wang y tho \n",
            "The. \n",
            "t a t \n",
            "hen t eme as in the t amure minghe m w y He oly then f wod mendin athe y s yhere t ns n. th \n",
            "st t \n",
            "\n",
            " ra\n",
            " rar. te Lo wousad n! hes ssat y s the s, \n",
            "terousa mon an d an the nd tre Souge t r a w s mino tondat Bun t ton wack \n",
            "\n",
            "pee sed ay baimowake de y \n",
            "rd \n",
            "\n",
            "Than watir ong \n",
            "Bad \n",
            "wiem llimar at \n",
            "\n",
            "' she se I a \n",
            "\n",
            " G\n",
            " Gon then by towim leen him d I hin Gas I o o wie t telsso the \n",
            "Bove \n",
            "\n",
            "Go chesangld omickito t t anco f to \n",
            "r Sarorn I hindorepllle. dsng as the onator \n",
            "\n",
            "\n",
            "\n",
            "Mowenoulde in islly read as the s sthad sst l \n",
            "\n",
            " ca\n",
            " cas wa s ly t as thinowhees sore ar \n",
            "Merind beralomoo s se s lser he stheteake che so t fo dan the ind Cainck \n",
            "\n",
            "Gantherere owe \n",
            "\n",
            "hes fe fr mar hed \n",
            "thisau h, hadoun bo s \n",
            "\n",
            "'And, d se we ul sthan. tepo \n",
            "\n",
            " Th\n",
            " The sack f t perene wad wefownd \n",
            "'Bu he tod Hed torknf tosshe tal. t asandiny s. s t thengr oman sonin of dor ano othailyos sed be s \n",
            "w I t he f \n",
            "pead o hed lthe wirow, s was. t. te y tonthind we ange \n",
            "\n",
            " wh\n",
            " who \n",
            "\n",
            "'I t \n",
            "ngr oof tal he waghifoars asthelas \n",
            "\n",
            "\n",
            "t Bind t hie ng ase idere. a pl ait s w he be bandes h Momaveman \n",
            "t lard idand cof the \n",
            "f e, t g Ment hid bus; s s m sto tas lie \n",
            "\n",
            "d s clar mamsas t t \n",
            "\n",
            " wh\n",
            " whe \n",
            "Thetren, 's the fend fom t ce tlir wathe I bu fopt dimowisthid tas. as lke g thid Sare u me ngle snes alid thtiss p ondstst o thad I w the wero mante fe \n",
            "I Tharerte whereroto \n",
            "Le d thello anpf \n",
            "a \n",
            "\n",
            " I \n",
            " I ousthe fo aicoft \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "it, r. houran he Homod mis meng hand \n",
            "\n",
            "woo \n",
            "\n",
            "t lomine towine Yis t w isad tootidr hee s muthind be thethes hevely \n",
            "' amrenowaswn y ththe weson I ncowe he s y the pldast t che w \n",
            "\n",
            " ca\n",
            " cas s: ghe t ad lstingad hethe \n",
            "\n",
            "d as st Tha fan winge ts he orend taye woremeit ily Ely \n",
            "wo tce p t te t waner s tt tan thasthasn! ll e \n",
            "\n",
            "tthanome ' nd e thed!' s y. Bowhindle t: ar r ind e furd lysd \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10): # Evaluation using user defined GRU\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "\n",
        "  print(evaluate(decoder, start_strings[start], 200), '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJhgDc2IauPE"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 6: Generate output on a different dataset\n",
        "\n",
        "---\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Choose a textual dataset. Here are some [text datasets](https://www.kaggle.com/datasets?tags=14104-text+data%2C13205-text+mining) from Kaggle \n",
        "\n",
        "* Generate some decent looking results and evaluate your model's performance (say what it did well / not so well)\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwD4MOAIM9ZF",
        "outputId": "0691bcd7-4641-46f1-ac60-549198e44167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46. (50 2%) 3.2379]\n",
            "Wh e,erreodAuta at.   r  u nsftawyl niYuhyeeo mYamnosaaWgonlneDn hnIoIs  er htkuaat etwearnAoSno ntop \n",
            "\n",
            "[94. (100 5%) 3.2782]\n",
            "Whs Lt\n",
            ".eeed euufaer\n",
            "einruphrr\n",
            "leao eeti .h pkuKs e ma\n",
            "Shoeata thn t uG t etr e ? leolko ae dti\n",
            "ue g  \n",
            "\n",
            "[141 (150 7%) 3.0779]\n",
            "WhDoeoi r hu ieefhe numa .ea'N d g.u   lWrtuvSduu tudoeasshyeg es e cee uhnhhtl rdanIn .  e?lhflph ea \n",
            "\n",
            "[188 (200 10%) 3.1563]\n",
            "WhonI as s n . tsoYkfa  rat hee de oao gksane f\n",
            " Weeh  s hb  s iedaun  ttIin e pkTgtro orA   ee n ta  \n",
            "\n",
            "[235 (250 12%) 3.1025]\n",
            "Wh thoesgiaoi  te\n",
            "tIen  .v     acawrts .fy.tm e ,Ie\n",
            "iouweu ., Iuu  iwnenll ea  ea to hmh en.ewIrI odr \n",
            "\n",
            "[282 (300 15%) 3.1407]\n",
            "Wh    ditaeegvt yl jtspstituno    utui elot s \n",
            " igldaf  ouo od  gortorn h.otee.d sTnone eoetlnmdrhibn \n",
            "\n",
            "[329 (350 17%) 2.9428]\n",
            "Wh ce tatit ye seootlun\n",
            "ty lo kee c I t at A t \"e aonmnaeorynos tn tngotouasot t mo tee m t I cuk fre \n",
            "\n",
            "[377 (400 20%) 2.8336]\n",
            "Whe y tokorota, f h \n",
            "wnre yogen st t Isorov tiag bedek s s Aas g\n",
            "yov te t nnison t d aset ad S uonu'r \n",
            "\n",
            "[424 (450 22%) 2.7642]\n",
            "Wh h! t at iwand ks w.elyato whasrre s ah. gye S.e wy m Ies tt!ht m t yt W h I A n shans'l? tinme sot \n",
            "\n",
            "[471 (500 25%) 2.7881]\n",
            "Wh\n",
            "Fiufev b fishone wse's fh,ao a tere tanme n pers b e,anyotiteeu amon Au ig n fewhesn basan ire web \n",
            "\n",
            "[518 (550 27%) 2.8645]\n",
            "Whege I tese yewince chotor\n",
            "Y m\n",
            "W\n",
            "I we whh se teic\n",
            "Wi'the t.oiskl.\n",
            "We cife tde t atak ofeipitove mtou \n",
            "\n",
            "[565 (600 30%) 2.8232]\n",
            "Whe Hhadou t Tet. re,  t ceyou nche youteg t ade logempy t\n",
            "I tano pe comh t\n",
            "W wou arel f atogel fovbt \n",
            "\n",
            "[613 (650 32%) 2.7066]\n",
            "Why t t s g, y. ywasit yeasale ye wor, we, hean bethe te anans w Is u th in I me the we se wedrou tse \n",
            "\n",
            "[660 (700 35%) 2.8002]\n",
            "Whis k cau t te b n yed ciu m!hisde y w t  T cison g mivl ou spi f Yot t sp yd aimiiukil t m tol Ir s \n",
            "\n",
            "[707 (750 37%) 2.7024]\n",
            "Wh.he f d.\n",
            "T\n",
            "Iothas le cer th,l on Wou ou litok m we't\n",
            "Arisororen d winnitesegol ire .\n",
            "W our Wh, the  \n",
            "\n",
            "[755 (800 40%) 2.5987]\n",
            "Wh gheghin l deso fomer p the.! med I'n ilhiin I f bowoxoun on't.\n",
            "Yen hife aze g y catece ye thalores \n",
            "\n",
            "[802 (850 42%) 2.5666]\n",
            "Whiyy tan t w kour s sis t w Ir ghamhe s s. t thilect ounsl jnth,u Sou imey oiv isege'ke tou n ge ali \n",
            "\n",
            "[849 (900 45%) 2.5551]\n",
            "Whe d fotistos bhe tawan in asy sstotopetr s ta the f bu tore are cen t as anf teo done to garou' t f \n",
            "\n",
            "[896 (950 47%) 2.6382]\n",
            "Who.hinso ire. he an.\n",
            "I t assin he the't ons t. w tro I meoud M o ouro le s min t t we thlenghinrit p \n",
            "\n",
            "[943 (1000 50%) 2.5311]\n",
            "Wheghouse dou as wer oce' bre e Kin the whe'yop n adkoghe'nr r ban w, aghee I as T, ke asitopongin' t \n",
            "\n",
            "[990 (1050 52%) 2.5340]\n",
            "Whe m y thim Ig is y son tre nrou s mlar ome'te t hare Cbloud mou t thore ne he couny re wo jur hat t \n",
            "\n",
            "[103 (1100 55%) 2.7831]\n",
            "Wh..\n",
            "Cl ythow s sitasp f Is monong tharr hete by hu y Ar ye'n ob y y thes y ithert? toulon f oe he nr \n",
            "\n",
            "[108 (1150 57%) 2.7235]\n",
            "Whalado ast itrou dou t houdyved t feopeeghe w Watou's roinriit hazouon bel ham'that? y kku ore. thep \n",
            "\n",
            "[113 (1200 60%) 2.6155]\n",
            "Whanry tharert thrlon n. ..\n",
            "I.\n",
            "At t e s houtotu aran s liri cutyres dond ou hed the te t be Gar! se d \n",
            "\n",
            "[117 (1250 62%) 2.6092]\n",
            "Wheeps ber y j athe, houthepor Int thery wk wau itheu fenpon t t!\n",
            "You's  I t Jin!\n",
            "We hitare fowou an  \n",
            "\n",
            "[122 (1300 65%) 2.6958]\n",
            "Whee t w se wan blomoumosr Moun worathiowemit. ke s band ot O  me. gan s been bbl?\n",
            "Ig,ere'lesge Won t \n",
            "\n",
            "[127 (1350 67%) 2.5874]\n",
            "Whathir. mil Ielsirered me ft tt hegu tof s.\n",
            "Weassn y ba he. Se ghy touse de wanpit t adtr pearleasor \n",
            "\n",
            "[132 (1400 70%) 2.3712]\n",
            "Whas tur.\n",
            "T fle kr it then nbaou havareang ours g aseryoua s fir ithe ntiv,e wheal a me ar in ar drow \n",
            "\n",
            "[136 (1450 72%) 2.5427]\n",
            "Whan's e sy snd me ot t ng pbeathle ithe u  than hes Sep tou gu car ge ds thuns isan got.\n",
            "Iti Savf t  \n",
            "\n",
            "[141 (1500 75%) 2.7615]\n",
            "Who are thinot borero lang be.\n",
            "O mout' w mee s an iror,ngitek, pfe Satha weru anang  i t,ou wr juwout \n",
            "\n",
            "[146 (1550 77%) 2.6589]\n",
            "Whe y te at. haryourou kale mtome houkongou .\n",
            "Sathet'ron' Id hireng at becarydoouate Yhereroukis ars  \n",
            "\n",
            "[150 (1600 80%) 2.4884]\n",
            "Wheend ath Hor borinn elyy hirere'.\n",
            "The'mese the womear in ou tou whe Iethe s an insouled red udtoura \n",
            "\n",
            "[155 (1650 82%) 2.5130]\n",
            "Whe at thag as  d haline st s ik.\n",
            "I Ithathethhex wouris Ighiiy ghpd hihas aghe's it rle who aver Kts  \n",
            "\n",
            "[160 (1700 85%) 2.4817]\n",
            "Whare ban wou  atouthe arelrowhe me sou esingi Sorend I ithatho It'rp to Wouret wo wafowou d hantous  \n",
            "\n",
            "[165 (1750 87%) 2.4799]\n",
            "Whet he s tomeridou o an T me wofan Her.\n",
            "Ared wk ad I t ting? an wome mo j e an r thent merirtamrou t \n",
            "\n",
            "[169 (1800 90%) 2.5283]\n",
            "Whisrepoudineneyok ase mus jt ke he. g t sit atatkr Wngouu wieu atist t tuter ino I mecou t le?\n",
            "Oirin \n",
            "\n",
            "[174 (1850 92%) 2.4594]\n",
            "Whay carer Ig T whaverlend as  gt ad so ano ng hoc!\n",
            "Whe the yo . ce st we athe ghye tr Ie e's ave Dan \n",
            "\n",
            "[179 (1900 95%) 2.6314]\n",
            "Whe co  ofle l mit sowingr  s Monrly macin ho c t u lethenkime.\n",
            "Wer be t led lereowo! p ang be y t.\n",
            "I \n",
            "\n",
            "[183 (1950 97%) 2.5209]\n",
            "Whowavlet, sou'tofs ghir ghiles by Itriv,tour, e thike I's bex be t anomnght's ssathese f n bet per s \n",
            "\n",
            "[188 (2000 100%) 2.5302]\n",
            "Whin ove a Wardin f geon's f ou bthhene che kins I'rongou boue heate Say be an y Ye, yres teabu on at \n",
            "\n"
          ]
        }
      ],
      "source": [
        "my_decoder = RNN(n_characters, hidden_size, n_characters, 5, my_GRU=True) # user defined GRU\n",
        "my_decoder_optimizer = torch.optim.Adam(my_decoder.parameters(), lr=lr)\n",
        " \n",
        "start = time.time()\n",
        "my_all_losses = []\n",
        "my_loss_avg = 0\n",
        "\n",
        "n_epochs = 2000\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  loss_ = train(*random_training_set(my_file_text, my_file_len, 200), my_decoder, my_decoder_optimizer)       \n",
        "  my_loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "      print('[%.3s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "      print(evaluate(my_decoder, 'Wh', 100), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      my_all_losses.append(my_loss_avg / plot_every)\n",
        "      my_loss_avg = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(my_all_losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "f2ovf93b8zxP",
        "outputId": "716e33a3-6c81-405c-c66a-c64203e14e89"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1dnA8d8zk33fN7Ky72tYFEREBFfUWitqrbZaa7V1qda31ldt7au1+r6tS62tdalbVdwp4sYmArIk7EsgAQJZgOwhIQnZzvvH3ITJBpMQkjA+388nH+6ce+7MMzfhmTPnnnuOGGNQSinlvmy9HYBSSqnTSxO9Ukq5OU30Sinl5jTRK6WUm9NEr5RSbs6jtwNoT0REhElOTu7tMJRS6oyRnp5eZIyJbG9fn0z0ycnJpKWl9XYYSil1xhCR/R3t064bpZRycy4nehGxi8hGEVnYzr6bRKRQRDZZP7c47btRRDKtnxu7K3CllFKu6UzXzV3ATiCog/3vGmN+4VwgImHAI0AqYIB0EVlgjCntSrBKKaU6z6UWvYjEA5cAL3Xy+ecAXxljSqzk/hVwYSefQyml1ClwtevmaeB+oPEEda4SkS0i8r6IJFhl/YAcpzq5VplSSqkectJELyKXAgXGmPQTVPsPkGyMGY2j1f5aZwMRkVtFJE1E0goLCzt7uFJKqQ640qKfCswVkWzgHWCmiLzpXMEYU2yMOWY9fAmYYG3nAQlOVeOtsjaMMS8aY1KNMamRke0OBVVKKdUFJ030xpgHjDHxxphkYB6w1BjzQ+c6IhLr9HAujou2AF8As0UkVERCgdlW2Wnx7JJMvt6t3waUUspZl8fRi8ijIjLXeniniGwXkc3AncBNAMaYEuAPwHrr51Gr7LR4YfkeVmUVna6nV0qpM1Kn7ow1xiwHllvbDzuVPwA80MExrwCvdDnCTvCwCfUNupCKUko5c6s7Y202oaHxRAODlFLqu8etEr2HTWjQpRGVUqoFt0r0dpvQ0KiJXimlnLldotc+eqWUasntEr123SilVEtuleg9tOtGKaXacKtEb7MJ9ZrolVKqBbdK9B42oVETvVJKteBWid5us2mLXimlWnGzRI/20SulVCtuluhtmuiVUqoVt0r0OupGKaXacqtEbxehXue6UUqpFtwr0dsEzfNKKdWSWyV6D7u26JVSqjW3SvQ20T56pZRqza0SvU5TrJRSbbmc6EXELiIbRWRhO/t+JSI7RGSLiCwRkSSnfQ0issn6WdBdgbdHZ69USqm2OrOU4F04Fv0OamffRiDVGFMlIj8HngSusfZVG2PGnlqYrtH56JVSqi2XWvQiEg9cArzU3n5jzDJjTJX1cA0Q3z3hdY5OU6yUUm252nXzNHA/4MqQlpuBz5we+4hImoisEZErOjpIRG616qUVFha6GFZLesOUUkq1ddJELyKXAgXGmHQX6v4QSAWecipOMsakAtcBT4vIgPaONca8aIxJNcakRkZGuhZ9Kzbto1dKqTZcadFPBeaKSDbwDjBTRN5sXUlEZgEPAnONMceayo0xeda/e4HlwLhTD7t9HjahUbtulFKqhZMmemPMA8aYeGNMMjAPWGqM+aFzHREZB/wDR5IvcCoPFRFvazsCx4fGjm6MvwWdplgppdrqzKibFkTkUSDNGLMAR1dNAPCeiAAcMMbMBYYB/xCRRhwfKk8YY05botc+eqWUaqtTid4YsxxH9wvGmIedymd1UH81MKrr4XWODq9USqm23OrOWE30SinVllsleg+bTmqmlFKtuVWit+k0xUop1YZbJXpt0SulVFtulejtNqHRgNGx9Eop1cy9Er1jaKdekFVKKSfulejtjkSvN00ppdRxbpXoPWzaoldKqdbcKtHbmrputI9eKaWauVWib27R6wyWSinVzK0Svd3ueDvaR6+UUse5V6K3um50qmKllDrOrRJ9U9eNtuiVUuo4t0r0du2jV0qpNtwz0WvXjVJKNXPPRK/z3SilVDOXE72I2EVko4gsbGeft4i8KyJZIrJWRJKd9j1gle8SkTndE3b7tI9eKaXa6kyL/i5gZwf7bgZKjTEDgb8AfwIQkeE41pkdAVwI/E1E7F0P98RsemesUkq14VKiF5F44BLgpQ6qXA68Zm2/D5wvjsVjLwfeMcYcM8bsA7KASacWcsd0CgSllGrL1Rb908D9QEed3/2AHABjTD1QDoQ7l1tyrbI2RORWEUkTkbTCwkIXw2rJrl03SinVxkkTvYhcChQYY9JPZyDGmBeNManGmNTIyMguPUdTom/URK+UUs1cadFPBeaKSDbwDjBTRN5sVScPSAAQEQ8gGCh2LrfEW2WnhbbolVKqrZMmemPMA8aYeGNMMo4Lq0uNMT9sVW0BcKO1/X2rjrHK51mjclKAQcC6bou+FQ+b4+1oH71SSh3n0dUDReRRIM0YswB4GXhDRLKAEhwfCBhjtovIfGAHUA/cYYxpOPWw22fNaaaJXimlnHQq0RtjlgPLre2HncprgKs7OOYx4LEuR9gJdm3RK6VUG251Z6zeMKWUUm25VaK36eLgSinVhlsleg+7JnqllGrNrRL98eGVOqmZUko1ca9ErytMKaVUG+6V6Jta9LrwiFJKNXOrRK999Eop1ZZbJfqmrhtdYUoppY5zr0Sv0xQrpVQbbpXom+a60T56pZQ6zq0SvZXnddSNUko5catE39yi164bpZRq5laJXvvolVKqLU30Sinl5twq0Vt5XrtulFLKiVslehHBwyY06Fw3SinV7KQLj4iID7AC8Lbqv2+MeaRVnb8A51kP/YAoY0yIta8B2GrtO2CMmdtNsbfLZhMaNM8rpVQzV1aYOgbMNMZUiognsFJEPjPGrGmqYIy5p2lbRH4JjHM6vtoYM7bbIj4JbdErpVRLriwObowxldZDT+vnRJ3g1wJvd0NsXWK3ifbRK6WUE5f66EXELiKbgALgK2PM2g7qJQEpwFKnYh8RSRORNSJyxQle41arXlphYWEn3kJLHjahURO9Uko1cynRG2MarO6XeGCSiIzsoOo8HH34DU5lScaYVOA64GkRGdDBa7xojEk1xqRGRkZ24i20pC16pZRqqVOjbowxZcAy4MIOqsyjVbeNMSbP+ncvsJyW/ffdzm4THUevlFJOTproRSRSRJpG0PgCFwAZ7dQbCoQC3zqVhYqIt7UdAUwFdnRP6O3zsNk00SullBNXRt3EAq+JiB3HB8N8Y8xCEXkUSDPGLLDqzQPeMabFjGLDgH+ISKN17BPGmNOa6G02vTNWKaWcnTTRG2O20E53izHm4VaPf9dOndXAqFOIr9M8bDbto1dKKSdudWcsWH30Ok2xUko1c79EL0KDLjyilFLN3C/R6/BKpZRqwe0SvYdddIUppZRy4naJ3ibaoldKKWdul+h1UjOllGrJ7RK93hmrlFItaaJXSik355aJXvvolVLqOLdL9DpNsVJKteR2iV5b9Eop1ZJbJnrto1dKqePcLtHrNMVKKdWS2yV6m7bolVKqBbdL9B7aR6+UUi24XaLXPnqllGrJlaUEfURknYhsFpHtIvL7durcJCKFIrLJ+rnFad+NIpJp/dzY3W+gNbtooldKKWeuLCV4DJhpjKkUEU9gpYh8ZoxZ06reu8aYXzgXiEgY8AiQChggXUQWGGNKuyP49tjt2nWjlFLOTtqiNw6V1kNP68fVTDoH+MoYU2Il96+AC7sUqYs8bDpNsVJKOXOpj15E7CKyCSjAkbjXtlPtKhHZIiLvi0iCVdYPyHGqk2uVnTY2EeobdPZKpZRq4lKiN8Y0GGPGAvHAJBEZ2arKf4BkY8xoHK321zobiIjcKiJpIpJWWFjY2cObeejFWKWUaqFTo26MMWXAMlp1vxhjio0xx6yHLwETrO08IMGparxV1t5zv2iMSTXGpEZGRnYmrBbsdl0cXCmlnLky6iZSREKsbV/gAiCjVZ1Yp4dzgZ3W9hfAbBEJFZFQYLZVdtroqBullGrJlVE3scBrImLH8cEw3xizUEQeBdKMMQuAO0VkLlAPlAA3ARhjSkTkD8B667keNcaUdPebcKY3TCmlVEsnTfTGmC3AuHbKH3bafgB4oIPjXwFeOYUYO8Vus2EMNDYabDbpqZdVSqk+yw3vjHX8q/30Sinl4IaJ3vGWtJ9eKaUc3C7Re1jdNZrolVLKwe0SfVO/fH2DJnqllAI3TPR+XnYAqurqezkSpZTqG9wu0Yf6eQJQVlXXy5EopVTf4HaJPtjXC4DSqtpejkQppfoGt0v0of6OFn25tuiVUgpww0Qf0tyi10SvlFLgjone6qPXrhullHJwu0Tv42nHx9NGebW26JVSCtww0QOE+nlRelRb9EopBW6a6IN9PSnTFr1SSgFumuhD/bwo0z56pZQC3DTRh/h56g1TSillcdNE76XDK5VSyuKmid6T8upajM5Jr5RSLq0Z6yMi60Rks4hsF5Hft1PnVyKyQ0S2iMgSEUly2tcgIpusnwXd/QbaE+rnSV2D4WhtQ0+8nFJK9WmurBl7DJhpjKkUEU9gpYh8ZoxZ41RnI5BqjKkSkZ8DTwLXWPuqjTFjuzfsE2u6O7asqpYA747f4rJdBdTWNzJnRExPhaaUUj3upC1641BpPfS0fkyrOsuMMVXWwzVAfLdG2UkhLsxgaYzhkU+288gn20+piyenpEpvzlJK9Wku9dGLiF1ENgEFwFfGmLUnqH4z8JnTYx8RSRORNSJyxQle41arXlphYaFLwXckxM/Rol+zt5ifvp7WbiLeW3SUAyVVHDpSQ05JdZdep76hkSueX8Xv/7P9lOJVSqnTyaVEb4xpsLpf4oFJIjKyvXoi8kMgFXjKqTjJGJMKXAc8LSIDOniNF40xqcaY1MjIyE69idaa5qR/flkWX+04zEvf7G1TZ1lGQfP2mn3FLfYt31XA04t3n/R1NuWUUXy0lmUZBbp0oVKqz+rUqBtjTBmwDLiw9T4RmQU8CMw1xhxzOibP+ncvsBwYdwrxuiS4eWKzOmwCr6zcR3HlsRZ1lmYUMCgqgFA/T9btK2mx71+rs3l6cSZLdh4+4ess31XY/Drb8spPWDenpIqpTyxlS25Zi/L6hkb9kFBKnVaujLqJFJEQa9sXuADIaFVnHPAPHEm+wKk8VES8re0IYCqwo/vCb1/TxViA318+kuq6Bl5Yvqe5rKKmjnX7Spg5LIpJKWGsbdWi355/BIBHF+6gpu74yB1jDI1OSXnZrgKGRAciAl/vdiT9sqpa5qflUNfQ2OI530vPJa+smg/Sc5vLnvw8g4EPfsagBxfxxfZD3fDOlVKqLVda9LHAMhHZAqzH0Ue/UEQeFZG5Vp2ngADgvVbDKIcBaSKyGcc3gSeMMac90Xt52PD3shMX7MP1kxK5clw8r6/Zz6HyGgBe/3Y/9Y2G2cOjmZQSTk5JNVf+bRX3vLuJgooaCiuOMWtYFPuLq3j4k23Nyf3llfsY+vDn3P5WOu+n57I9/wiXj4tjdL9gvt5dSH5ZNVf//Vvuf38LL32zrzkeYwwfb8wD4KsdhzHGUHq0lldXZTM5JQwfTzurs4pO92lRSn1HnXR4pTFmC+10txhjHnbantXBsauBUacSYFddNCqWcYkh2GzC3bMGsWBzHs8tzeTmaSk8sySTi0fFMCEpjGBfTx63CZmHK9mUU8a0gREA3HJOf4bHBfPskkw87Tb+66KhPLc0i34hvqzdW8KirY4W+IzBUdTUNvDs0izOfmIpAd4ejEkI4bmlmVw6OpYgX0+yCio5UFLF5JQw1u4rYXv+EZZmFFBd18AfrhjJAx9uZeehit44TUqp7wBXxtGfkf736jHN2wlhflwzMYG31h5gfloOvp52fjd3BAADowLZ8NAFHCiu4rK/ruSFrx1dPMPjgpicEkZdQyMvLN/Dt3uLKa+u482bJzMsNpCVWUUcKq9hWGwgIX6eFB+tJSbIhwtHxuDjaWfWn7/mnCeXAeDracfbw8aT3x/Nef+7nL8tz2LN3hLOGxLJ4OhAhsYE8p/N+RhjEJGeP1lKKbfmtom+tV9dMARvDzseduHCETFEBfo07wv29WREXBBRgd5kFVSSGOZHkI/jgu79c4ZQV9/ISyv3MWtYNKPigwGYMSSq+fi4EF8eu7LlF5fnrxvPlrxyfD3tbMktY3R8CEnh/qQmhbFo6yEiAry5d/YQAIbGBvHW2gMcLK8hLsT3dJ8KpdR3zHcm0Yf5e/HQpcM73G+zCecNieLdtBxG9gtqLhcRHrxkGGMSQpjcP8zl15s1PJpZw6PblP/p+6PZW1jJOYMi8fJwXCIZFhMIQMahI5rolVLdzi0nNeuqmcMcrfQRccEtykWEy8bEtfgW0FUpEf6cPyy6OckDDLYS/c6D2k+vlOp+muidnDs4kqsnxHPp6Ngefd0gH0/iQ33J0AuySqnT4DvTdeMKH087TzldxO1Jw2KDyDh4pFdeWynl3rRF30eM7hdMVmElBUdqejsUpZSb0UTfR1w4MgZj4LNteoesUqp7aaLvIwZFBzIkOpCFW/J7OxSllJvRRN+HXDo6lvXZpc1TNSilVHfQRN+HXGKN9vls28FejkQp5U400fch/SMDSAr349s9xSevrJRSLtJE38dMSg5jXXZJi+mQlVLqVGii72MmpYRRVlVHZkElL6/cd9IFTZRS6mQ00fcxU/qHA/Dskkz+sHAHr6zad5IjlFLqxDTR9zHxob7EBvvw6VbHBdnteXq3rFLq1LiylKCPiKwTkc0isl1Eft9OHW8ReVdEskRkrYgkO+17wCrfJSJzujd89yMiTEpxzJKZFO5HZkEF1bUNJzlKKaU65kqL/hgw0xgzBhgLXCgiU1rVuRkoNcYMBP4C/AlARIYD84AROBYU/5uI2LsreHc1b2IiV4yN4/45Q2k0jumLlVKqq06a6I1DpfXQ0/ppPSTkcuA1a/t94HxxLJV0OfCOMeaYMWYfkAVM6pbI3dhZA8J5et44xiQ4pkvelq+JXinVdS710YuIXUQ2AQU4Fgdf26pKPyAHwBhTD5QD4c7lllyrrL3XuFVE0kQkrbCwsHPvwk31C/ElxM+THfk68kYp1XUuJXpjTIMxZiwQD0wSkZHdHYgx5kVjTKoxJjUyMrK7n/6MJCKMjAtmm16QVUqdgk6NujHGlAHLcPS3O8sDEgBExAMIBoqdyy3xVply0Yh+Qew6VMG+oqO9HYpS6gzlyqibSBEJsbZ9gQuAjFbVFgA3WtvfB5YaY4xVPs8alZMCDALWdVfw3wVzx8Th62Xn4me+YVlGQW+Ho5Q6A7nSoo8FlonIFmA9jj76hSLyqIjMteq8DISLSBbwK+A3AMaY7cB8YAfwOXCHMUbHCnbCiLhgvrh7OmH+Xry6OhuAxkaD43NUKaVO7qRLCRpjtgDj2il/2Gm7Bri6g+MfAx47hRi/82KCfZg+OIKFWw7S2Gi45sVvGRwdyGNXjurt0JRSZwC9M/YMMS4xlIqaelZmFbE+u5QFm/KprW/s7bCUUmcATfRniPGJoQD8ZfFuACqO1bN6T1FvhqSUOkNooj9D9I/wJ8jHg40HyogN9sHfy84X2w/3dlhKqTPASfvoVd9gswnjEkP5enchM4dGUVZdx5fbD+HvZSc1OZQLR8b2dohKqT5KW/RnkKbum/OGRHHZ6FiKj9by0sp9PL4oQ0fhKKU6pC36M8iV4/pxsLyaaYMi8Paw8eU901mxu5D/+XQn+4qO8tm2Q1TXNnDfnCG9HapSqg/RFv0ZJDHcjyeuGo2Ppx0RYXB0IHNGxADw8cY8nlmSyQtf7yGvrLqXI1VK9SWa6M9wCWF+9I/052/L91Bb34gxhje+3d/bYSml+hBN9G5gxuAo6hsNUweGM2dEDO+sP8CmnDJdsEQpBWiidwuzR0QDcPO0FG6elsKR6jqueH4Vlzz3DTV1DRhj9OYqpb7DpC+O1khNTTVpaWm9HcYZJbe0ivhQPwD2Flayak8xD328jdvOHcD2/HLySqtZdNc5+Hi6vsDXtrxygnw8SQz3O11hK6W6iYikG2NS29unLXo30ZTkAfpHBnDDlCQuGxPH37/ew8qsIvYWHeXtdQfaPXbZrgIKKmpalDU2Gm56dT2PLtx+WuNWSp1+mujd2IMXD2NcYghPXzOWKf3DeH7ZnuZ++2155WzNLefxRTv58avreejjbS2O3Z5/hKLKY+w8WNEboSulupGOo3djMcE+fHT7VADiQny5+u/f8s9v9nLB8Gjm/nUljVavXb8QX5bsLKC48hjhAd4AfL3bMfd9Xlk1FTV1BPp49sp7UEqdOm3Rf0dMTA7jklGxPL8si/vf30KQryfPXjuOF2+YwKs/nkh9o+HjTfnN9b/eXYiHTQDYfVhb9UqdyTTRf4c8dOlwPO02tuaVc8+swcwdE8fsETEMjg5kTEII89fn0NhoKK+uY8OBMi4bEwdAxqGOE31VbT3lVXU99RaUUl3gylKCCSKyTER2iMh2EbmrnTq/FpFN1s82EWkQkTBrX7aIbLX26VCaXhQT7MPj3xvF3DFxXD85scW+G6YksetwBQ98uJUnPttJQ6PhusmJBHh7sPsEif7Otzdy/ctrTnfoSqlT4EoffT1wrzFmg4gEAuki8pUxZkdTBWPMU8BTACJyGXCPMabE6TnOM8bo5Ol9wNwxccy1WurOrhrfj/3FR3luaRYAP5maQmpSKIOjA9q06Ktq67GJcKCkisU7C7AJ1NQ1dGroplKq57iylOBB4KC1XSEiO4F+ONaBbc+1wNvdFqHqESLCvbOHMDAqgNhgXyalhAEwJCaQz7Yd4vNtB4kN9mVMQgj3zt/M+uxShscFAdBoIKugkpH9gnvzLSilOtCpPnoRScaxfuzaDvb7ARcCHzgVG+BLEUkXkVtP8Ny3ikiaiKQVFhZ2JizVjS4f2685yQMMjg6krKqO297cwIMfb8UYw+o9xRRVHmPF7kKm9HfU1Qu2SvVdLid6EQnAkcDvNsYc6aDaZcCqVt0204wx44GLgDtEZHp7BxpjXjTGpBpjUiMjI10NS51mM4dGMSk5jLMHhLPzYAUZhyoor67jjvMGcO2kBJ76/hi87DZ2tdOPX1Vbz+OLdrItr7wXIldKNXFpHL2IeOJI8m8ZYz48QdV5tOq2McbkWf8WiMhHwCRgRdfCVT0tKdyf+bedxbKMAlbvKebNNY6ZMS8aGdvcVTMgKoBdrVr0RZXH+Pmb6azPLmVzThnv/uysHo9dKeXgyqgbAV4Gdhpj/nyCesHAucAnTmX+1gVcRMQfmA1sa/8ZVF82LjEEgA835OHlYWNwdGDzvqExgc0t+tr6Rn7yr/VMfGwxGw+Ucf7QKNbuK+nWVv389Tnc//7mbns+pdydK103U4EbgJlOQygvFpHbROQ2p3pXAl8aY446lUUDK0VkM7AO+NQY83m3Ra96TIifFwMi/amua2BYbBBeHsf/dIbEBHKwvIby6jrW7C1maUYBN0xJ4tM7z+HP14zFz8vOK6v2AfD8siwmP76YhVvyO3qpdr3+bTa/+WALNXUNPPlFBvPTctvtLlJKteXKqJuVgLhQ71/Av1qV7QXGdDE21cdMSAplT+FRxsS3HF0zxGrd7z5cwZKdh/HxtPHbi4c1D7f8QWoC/1qdzZ6CSjbnlhPu78Uv/r2Rg2U1/HR6f47VN2AXwcPecbvj7XU57Dx4hIKKYxRV1gLwwYZcfnvxsNP0bpVyH3pnrHLZhCTH4uSjWg2jHNEvCLtN+M/mfBbvLGDawIgWY+r/68Kh/OqCwewvqeLqCfGsfmAm0wZG8M9v9nKsvoHL/7qKe+Z33BVTVVvPrkNHEIGlGQUMjQnkguHRfLQxj/qGrs+zX1ZVy6/f20zp0douP4dSZwJN9Mpls4ZFc8noWGYOjWpRHhXow7WTEnhjzX7yyqo5f1h0i/2+XnbuPH8QGx+6gKeuHoO3h50fnZVEQcUxfvPBVjIOVfCfzflkdjBEc0tuOY0Gfj1nCD6eNu44byBXjY+nsOIYy3d1fSjulzsO8156Ll/uONTl51DqTKCJXrksPMCb568b3zzDpbN7Zg0mwMvRE3h+qw+CJo7r+g7nDY0iIsCbjzbmkRzuh5+XnReW72n3uI0HygC4dmIimx+ZzWVj4pg5NIr4UF+e/CKDui626tOyHaOA12eXNpc9sziTe97d1KXnK6w4xj9XOL6l9DVLdh6mps71uD7ZlMeW3LJTes2vdxdSUaPzIPUFmuhVtwgP8OYPV4zklmkpRAX5nLS+p93GVRP6AXDn+YO4blIin2zOZ3NO2+Sy8UApKRH+hPp74e3h6BLy8rDxyGUj2H24ktdWZ7c5pqq2nm/3FANgjKGkne6ZtP2OBL/eSvjH6ht4eeVeFm7J71RSbPL4op08tmgnTy/OpK6hsc03lA/Sc3nj27axnm6bcsq4+bU03kvLcal+Y6PhgQ+38uySrC6/Zk5JFTe+so5XVmZ3+TlU99FEr7rNFeP68d+XDne5/s+mD+C/LxnG3DFx3DZjALHBPtz46rrmBLkys4g31+xnw4EyxiWEtDl+1rAozhsSyTOLM9sk5n98vZdr/7mG3Ycr+GRTPpMfX0x20fEBYcWVx9hbeJSYIB/2F1dRcKSG5bsKOVJTT12DYefB9u8J7GjpzczDFXy8KY8wfy/+8fUeLnrmGy74ywq255c3H/fnr3bzv1/upqHx1JbvbGw0bM0t5+vdhRRWHDtp/cU7DgOwOde1Ia6HjtRQVdvQ4TlwVlPXwKP/2UFRZcs40vY7Pjy/3XvmTHGVU1LFnsLK3g7jtNBEr3pNmL8Xt5zTHw+7jYgAb966ZTKedht3/HsD5dV1/PLtDfz3x9soqjzWPI7fmYjw46kpVByr5+vdhRhjmrsKPtt2EICFm/N5d30OdQ2mxZDOdKs1f8s5KYCj++bjjXkEeDu6n7a0kxRLjtZy1h+XMvWJpfxx0c4WSf/pJZn4edr55I6pxIf6UWZN3bw5x/E8ewqPkldWTXl1XXPyb61pIfeT+WBDLpf9dSU3vrKO299KP2n9xTsdib71vQzl1XXc/c5GVu9pmYybkl1eWTVlVY5vQsYYtuWVk1NSRTeGEXkAABYVSURBVKPTB9W3e4t5ZdU+Fm5uOVw2zeoO23CgrEvfjnrDve9t5tbXW06wuzKzqE92xXWWJnrVZySF+/OHyx3dMT96eS2lVXU8duVIbp6WwqWj2864CXDWgHBC/TxZtPUgT3yewVl/XMqyXQXsPlyJh014Ny2HNfscXTiLth7CGENWQQVLMwrwstu4dlIivp52Xv82myUZBXx/QjyRgd7tdiE99UUGhZXHSAjz5R8r9jbfDZxddJRFWw/yo7OTSQjz4/O7z2HVb84j0NuDHQcdyXXF7uMXjVdlFbd57sNHapj4P4u55bW0FqOAjDHc8e8NLNp6sLnsk035JIb5cdu5A1ifXcrGA6Vtni+vrJo5f1nBS9/sJeNQBaF+nmQWVDYn3araem7+13o+3pTPI59sb5G89xQcb9XusFr1X+04zKXPreScJ5dx33vHR0jtyHfs39TqfKXvL8XPy05tfWObfX1RU5xNH8jgmKjvhy+v5YP0vF6O7tRpold9ypwRMaQmhbI5t5wZQyK5fnISD106nFB/r3bre9ptzBkRwxfbD/HSN/uoPFbP7W9uAOD2GQM4fOQYxjjm299x8Ah3v7uJWX9ewTvrcxibEIK/tweT+4exdl+Jo+vo7GTGxAezudWFyA0HSnlnfQ4/PjuZZ+aNA2BZhiN5/2t1Nh424cdnJwPg5+WBt4edYXFBzYnwm8xC+kf4MzQmkFVZbbsz3l53gMraelZkFjL3+ZUcKncs1r49/wifbjnIp1scib6o8hir9xQxd0wcv5g5kEAfD55dksnji3Yy36kPfv76HHYdruB/Pt0JwE+n96eh8XiX1IMfbWPDgVK+N74fmQWVfGl174Dj20fTDXFN8S/NKCDQx4Mrxsbx8aY88q1k2PQtwTmZl1fXsetwBddOSkQE1uxt+8HW1+w4eITaesdF/VWZjt9P0zevpg/rE0nfX8J1/1zT/A2or9FEr/oUEeGhS4cTFejNvRcMcemYi0fFUlPXSKCPB7fPGEB1XQNjE0K4aWoKdpswNiGE22YMAByt4R+kxvP8deP5vx847uV7+pqxLL9vBsvvm0FKhD9j4kPYW3SUI1Y30O7DFfz0tTRigny4a9YgooN8GB4bxLKMAsqr65iflsNlo+PaXIQeHhtExqEKauoaWLO3hHMGRTB1YATrsktadGfUNTTy77UHOHdwJPN/dhalR+u44eW1lB6t5fNtjqGfTd8ePtt2iEYDl4yOJcDbg+smJ7JsVyEvrtjL44t2UlvfiDGGDzfmMiEplFH9ghkRF8TlYx0XvrfllfPl9kN8tDGPX84cxJNXjSYp3I/nl2U1dxvtKaxkeGwQ0UHe7Mg/gjGGbzKLmDoggntnD6HRwHtpuYDjgwggu9jRv33F86v474+3YYxjQrzhsUFdTvS5pVVc+PQK9p5Cv3ldQyM5JVUnrbfB6soL8PbgG+uDuGkdhoyDJ78De/muQlbvKeYx64P1REqO1lJQUdMixic+y2j+8DwddHFw1eeMSQhh3YOzXK5/1oBwJqeEcd3kRC4eFcu+oqNcMjqWMH8vnvjeKPpHBtAvxJcrx/XDx9POY1eMxGY7PtQzxM+LEL/j3xhGJ4RgDFzw568praqjodEQ7u/Fm7dMbl4kfebQKF74eg8PfbyNqtoGfjItpU1cw+OCqKpt4NVV2VTXNTB9cCQ2EV5euY+fv5nONRMTmTEkkvfScymoOMYfpyQxLjGUF380gZteWc+9723mgJWk9hUd5Vh9A59uyWdApOObAcDPzx2At4edEF9PHl24gxW7Cwny9SSnpJp7Zg3m8rH9OFbfgK+nnTB/LxZuOciewqMMiw3ijvMG4mG38fNzB/CbD7eyIrOIcwdHsqewkmkDIwn182THwSPN3Rm3nzeAhDA/pg2MYH5aDjeencSBkirOGRTBN5lF3PfeZjbllLEpp6z5A3bqwAheXbWP3NIqfD3tfLwpn/LqOq4YG0dSuD8/eyONqQMj+PHUtufv2z3FZByq4N31OTzQzh3QGYeOsCW3nO+Pj2df8VHyy6o5Z9DxmW8raur46etppO8vZdl9M4gP9evwb2jDgVLign2YlBLGN5lFNDp9+9l1uAJjTIvhwa1lFzt+T++l55IQ5seIuCBmDo1q95h7529ia94RFt05jaggH1ZmFfH3r/fgYRPum+Na46azNNGrM56n3dZidswXfjihefvq1ITm7b9cM9al55uQFMqk5DBC/DxJifDHZhPmTUwgKdy/uc55Q6P467IsFmzO5/YZA9pddGV4rGNhlr8s3k1SuB/nDo5ERLh9xgDmp+WybFc6nnahrsEwODqAGUMc9x+cPSCC/7poKH9Y6FjbJzUplLT9pWzNLWd9dik/m96/OYGE+HnxqwsGU9fQyHNLM/lwYy51DQY/LztzRsRgtwl+1v0NI/sFs2J3IXHBPjwzb2xz98z3xsfzzJJMnl+axfjEEA4fOcaAKH9ij/mwIrOITzY5+qinW0n0mokJ/PLtjTz5xS4Arp2UyMqsIjYeKGPWsGhmD4+mrLoWf28Pbjo7mddWZ/PHRRnsLznKtjxH8lywKY8fnZXM4p0F7DxYwU1nJ3PnO5sYHBXAL88fBNA8l9GCzfn814VDsdmE55dlcaC4ij99fzT/+8VuFu88zEcb8tiUU0ZtQyObH5lNgLcHlcfquf6ltWzPP0JDo2FZRgE3nJXc4e9844EyxiWFMm1QJB9vymfnoSNkHKzA0y5U1NSTX15DvxDfDo8/UHyUicmhVNU28OevdgNw5bh+PHHVqOYhweC45rIxp4yyqjp+8e+NvPXTyc2jolZkFmqiV6qnBHh7MP+2E0+rPDYhhMHRAYxPDOXXHfznHBQdgIdNqK1vbG49A9xvTQmxMquI5bsKGR0fzEUjY7E7fcv48dnJLM04zOo9xfxi5kBuenU9b6zZT0OjYdqgiDav5Wm3cenoON6wppH+9Zwh+Hu3/O/9oylJ9Avx4f45Q1tc8/DysHHr9P78/j87eHmlY/K5AZEBhPt78bflWTy3NIuUCH8Swhwt4otGxjCqXzD/XnsAgInJYQyOCmTX4Qp+dm5/JiYfX7gmLsSXn0xLab4Z7sUbJhDo48m1/1zDowt3EODtQV5ZNa9/u5//bM4nOdzveKI/XIFN4GB5DeuzS0iJ8OeZJZk0NBr++9JhbDhQSmKYH2v3FdMv1Jeckmq25JQxMSWMn7+Zzvb8I/zjhxN4bNFOlmQUcM3ERLbmlTdP5QHw77UH+HZvMXll1fxkWgrnDo7Ewya8uiqbQ0dquGB4NF/tOMyuQ0dOmOizi6u4dHQsj14+krKqWv699gD/99Vuauoa+Nv142loNDQYQ8GRY5RV1TFtYAQrs4p46Zt9LN55GJvA1rxySo7WEtbB9ahToYleqS6w24TP75reoguoNW8PO4OjAzlSU8eV4/q12OdhtzFjSFRzK741m0342/UT2HWogjEJwdhtwqdbDuLtYWN8Ymi7x8yblMCCzfncM2sQN7XTFTJreDSzhke3cyTMm5jIS9/s4+nFmYAj0Q+MCuCLu6fz7NIspg4IbxH7E1eNYu5fVxER4EVkoDdzx8axLa+c1KS2sf18xgCW7yrkirFxzB4RA8BNZyfzxpr9vHjDBG56dT3/86nj20t2cRUFFTVEBfqw82AFF46MYVlGIa+v2U9kgHfzBdMP0nMpOVrLfbOHcP6wKLzsNsb94SvS95eyJa+cbzKL+NNVo5g1PJpv9xbzxpr9/Pajrbyfnsund05jRFwwuaVVPLJgG76edsL9vTh3cCSRgd7MGRHD++mOaxCXj43jqx2HyThUwcyh0WQVVLI1r4wrx8VTcKSGtP2lnD0gnPLqOpLD/bHbhPAAb355/iA87Db+9HkGTy/O5P30XIbHBXHVeMffwX1zhuDtYeP/vtxFfaPhhilJvLFmP6uyirisnTWdT5UmeqW66ERJvsnT88ZitwmeJ5iZsyPBvp7NyzqmRPiTVVDJWQPCO1yEfURcMJsevuCEfckd8fWy89nd5/Bhei77S6pIiXB0Uw2KDuS5a8e1+1p/uHwk9Y2OxHvHeQM7fO4gH08+u+ucFmWPXDac284dQEywD+cOieSrHYeZkBRK+v5S1u8rZUr/MMf9EwmhxAb7Nn/TuGhkDEt2FvDiir2Ao5st2roIPjg6gA0HSskvq2FCUijXTEwEHFNyvLxyX3PyXpZRwIi4YP66NAtB+Pzu6cQ5tdavn5LIp9Zw1kkpYcQF+zR3Iz3w4RbWZ5cypX84zy7J5O11Obxw/XgAEsNbXgO4dXp/lmYc5pkljg/PQ0dqiAjwxm4ThsYE8tClw/nmLyuwieGuWYNYsDmfFbsLNdErdaZxXqDl1J4ngKyCSs4e0LbbxllXknyTIB/Pdr8JdOS6yYldfi0RISbYkaDnTUxgdVYRf7pqNJc9t5L12SWE+jkueg+JCeSWcxxdKh9syOW+2UMorqxlXXYJgT4eDIoKaH7O8YmhfLghj9qGRn4/d0RzeWpyGIE+HsQE+eBht7FsVyGXjo7jvfRcbpiS1CLJA5zVP5wBkf6UV9cRFejDkJhAtuSWszKzqHlepIWbD/LFdkff+ltWF1ay0zUccHzr+/MPxvK35XuYMSSSn72RzvvpOQyKCsDH005yhD8PXDyU3NJqIgK8mTbQcVH7ZBd+u0ITvVJngMHRgSzaeoipA8NPXvkMc/6waLb8bg52mzAuMYR1+0pItK4HDI0JRESYPjiS6YMdF4On9A9jXXYJ4xNDW3yrGp8Uyjvrc7CJY8htEy8PG2//dAoRAd68ve4Azy3N5LcfbcXbw8bt1rBbZyKOBN00P9JlY+L41fzN/Phf64gI8CLY15PnlmZypKYegJXWcMymmJ0lhPnxx++NwhhDUrgf+4urWly4dx5t9KOzkrhwZAyNBuzdm+ddWkowQUSWicgOEdkuIne1U2eGiJQ7rUD1sNO+C0Vkl4hkichvujd8pb4brk5N4P4LhzAyru3oHnfQdCF6YnIYOw8d4Yvthwj18yQysO1MqVP6Oz7sJrS6HtB07eLsARFtjhvZL5iYYB/OGxpFo4HVe4q547yBHU7ANyYhhPOsWVi/Nz6ep68ZiyDccd5A5o7px5Gaevy97Fwy2vGBEh3kja9X+11q4PjwuGiko27r9RyaTO4fzmVj4lpclO8urnQc1gP3GmOGA1OAO0SkvZmrvjHGjLV+HgUQETvwPHARMBy4toNjlVIn0C/El9tnDHTpusCZrOnC6tp9JYyKD2m3C2NiShg/PSeFqybEtygfEOnPleP6cdu5bVvpTUb3CyYiwIv4UF9ubufeh45cMa4fmx+ZzY+npnDJ6Bgr1mhmDXN8GCSF+Z/ocACuGt+P6CBvpg48cffb6eDKUoIHgYPWdoWI7AT6ATtceP5JQJa1pCAi8g5wuYvHKqW+Y0bHh7Dld7PJKqgkNrj94YyedhsPXtK2vSgiJ71XwmYTXvxRKoHeHh1e1O5IU4t9YFQgv587gmmDIgj0caTQpPCOb8ZqMig6kLW/df1GwO7UqT56EUkGxgFr29l9lrUIeD5wnzFmO44PBOdJsHOByV2KVCn1neDtYWfEaeyi6mh4amfcaM1rBPDgxcOYmBLWceU+wOVELyIBwAfA3caY1hNVbwCSjDGVInIx8DEwqDOBiMitwK0AiYldv5qvlFI96afT+/d2CCfl0uBeEfHEkeTfMsZ82Hq/MeaIMabS2l4EeIpIBJAHJDhVjbfK2jDGvGiMSTXGpEZGRrZXRSmlVBe4MupGgJeBncaYP3dQJ8aqh4hMsp63GFgPDBKRFBHxAuYBC7oreKWUUifnStfNVOAGYKuINK2a/FsgEcAY83fg+8DPRaQeqAbmGcecp/Ui8gvgC8AOvGL13SullOoh4srSZT0tNTXVpKWlnbyiUkopAEQk3RiT2t4+XXhEKaXcnCZ6pZRyc5rolVLKzWmiV0opN9cnL8aKSCGwv4uHRwBF3RhOd9G4Oq+vxqZxdY7G1XldiS3JGNPuTUh9MtGfChFJ6+jKc2/SuDqvr8amcXWOxtV53R2bdt0opZSb00SvlFJuzh0T/Yu9HUAHNK7O66uxaVydo3F1XrfG5nZ99EoppVpyxxa9UkopJ5rolVLKzblNou8ri5B3tJi6iPxORPKcFlC/uJfiyxaRrVYMaVZZmIh8JSKZ1r+nvgRP52Ia4nReNonIERG5uzfOmYi8IiIFIrLNqazd8yMOz1p/c1tEZHwvxPaUiGRYr/+RiIRY5ckiUu107v7ew3F1+LsTkQesc7ZLROb0cFzvOsWU3TQjbw+fr45yxOn7OzPGnPE/OKZA3gP0B7yAzcDwXoolFhhvbQcCu3EsjP47HEss9va5ygYiWpU9CfzG2v4N8Kde/l0eApJ645wB04HxwLaTnR/gYuAzQIApwNpeiG024GFt/8kptmTner0QV7u/O+v/wmbAG0ix/t/aeyquVvv/D3i4F85XRznitP2duUuLvnkRcmNMLdC0CHmPM8YcNMZssLYrgKbF1Puyy4HXrO3XgCt6MZbzgT3GmK7eGX1KjDErgJJWxR2dn8uB143DGiBERGJ7MjZjzJfGmHrr4Rocq7j1qA7OWUcuB94xxhwzxuwDsnD8/+3RuKyFkn4AvH06XvtETpAjTtvfmbsk+vYWIe/15CptF1P/hfXV65We7h5xYoAvRSRdHOv0AkQbYw5a24eA6N4JDXCsQub8n68vnLOOzk9f+7v7CY6WX5MUEdkoIl+LyDm9EE97v7u+cs7OAQ4bYzKdynr8fLXKEaft78xdEn2fI20XU38BGACMBQ7i+NrYG6YZY8YDFwF3iMh0553G8V2xV8bcimO5ybnAe1ZRXzlnzXrz/JyIiDwI1ANvWUUHgURjzDjgV8C/RSSoB0Pqc7+7Vq6lZYOix89XOzmiWXf/nblLond5EfKeIO0spm6MOWyMaTDGNAL/5DR9XT0ZY0ye9W8B8JEVx+Gmr4LWvwW9ERuOD58NxpjDVox94pzR8fnpE393InITcClwvZUgsLpGiq3tdBx94YN7KqYT/O56/ZyJiAfwPeDdprKePl/t5QhO49+ZuyT6PrMIudX312Yx9VZ9alcC21of2wOx+YtIYNM2jgt523CcqxutajcCn/R0bJYWray+cM4sHZ2fBcCPrFERU4Byp6/ePUJELgTuB+YaY6qcyiNFxG5t9wcGAXt7MK6OfncLgHki4i0iKVZc63oqLsssIMMYk9tU0JPnq6Mcwen8O+uJq8w98YPjyvRuHJ/ED/ZiHNNwfOXaAmyyfi4G3gC2WuULgNheiK0/jhEPm4HtTecJCAeWAJnAYiCsF2LzB4qBYKeyHj9nOD5oDgJ1OPpCb+7o/OAYBfG89Te3FUjthdiycPTfNv2t/d2qe5X1O94EbAAu6+G4OvzdAQ9a52wXcFFPxmWV/wu4rVXdnjxfHeWI0/Z3plMgKKWUm3OXrhullFId0ESvlFJuThO9Ukq5OU30Sinl5jTRK6WUm9NEr5RSbk4TvVJKubn/B/h6N3aSxCP3AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RFU5z6nNNMs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c18bbc-f61c-4f9f-d79a-f11cf318ff45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Th\n",
            " Thoue!\n",
            "Kofote Werou as Denofo, bar wem c ber.\n",
            "Nou thbestaf t  o thir t Asevetak Yhe so wh. cabean. Anoki!\n",
            "Elernd Aley ger wourr, werire,om o an pe tou. m.\n",
            "Nal s ..\n",
            "Perir s peng m whe adomn'nd Fed toen \n",
            "\n",
            " Th\n",
            " Thoorend Buwe wo!\n",
            "Id s me'sou jngathe n's we thame g  hele whe rite on'iry tangltle en ou g theld y u Ar you hedtopoure t so ano y r d dbe an?\n",
            "Tarele hsour acour wure o tet.  the t w Ye!\n",
            "Alive s be so \n",
            "\n",
            " G\n",
            " Gayo che f thar fowave te'ld he wenghe Me be'sou's hokd!\n",
            "I'serer Thirl wonds ourinrou bis be s c!\n",
            "I lund heser cu sut theerperou  ber to t g'mor Fereerouay ewor T you thebouthe thed'tave He an'sor t t \n",
            "\n",
            " Th\n",
            " They wangou tttes ba't  Iro af ouamd thi ipo owon's .\n",
            "Is,e Wher tr, lo Fantirrtou Wthe Shavas coureroun...\n",
            "Were f Sor Fati his 's d f i bathe be's wiy wer,othome tou tt acas  war aree s taco  teacou   \n",
            "\n",
            " I \n",
            " I wo fin t tou visoou o yong ter ber the wo wesou o yo ou Dhoran malaree hpor l tr of o d basour Thoumevete w Fand a a'thar wson me p.\n",
            "Wh?   he spouy m heof teyire g wen,ou keao wher tir tabei he met  \n",
            "\n",
            " wh\n",
            " whancarourinp  pp Irkin!\n",
            "I, s s be lis ingherk tc htyof f f tho bisouvein'll the wirre aneirle's y t! arort jndoo cis t Bil Eamel? haom soudoo oul sbeghe t ben fd wond u Fat ar t trtetorowhi!\n",
            "Wacu too \n",
            "\n",
            " he\n",
            " he te whe ace wu e irthers irirak eroo, hed cr do Watanse cle tonges wou. Anou t y t  thr torp Faddor j to hber wawor til fthe Ar u! f one ci'rel wouredo, alathe s Loroke the y l be ocer mls f . s.\n",
            "Wn \n",
            "\n",
            " Th\n",
            " Theru lebed yps s y y f s t'r dof tepereirin n f p s mhe's or bpte's ing te whees,ou.. whas tho Longherarto  co touren! o ar re,, .\n",
            "Es y whou ou! tro thergrd s womous reavr do!\n",
            "No!\n",
            "An t s t'ter the! c \n",
            "\n",
            " I \n",
            " I as bocicim  has wor  l t hi, ores sou s s t mterte cou'sou!.\n",
            "Ct!\n",
            "The  thehedp!\n",
            "Bu e we okisou n, your outor trlel gounerind hend bet y hyorere il the Ju rise abethe's I o tethe.\n",
            "Wher Thee ihin bifo  \n",
            "\n",
            " ca\n",
            " can dor jir s s inert bet allr I ilerl ak gherareary have ftibando ber. wig!\n",
            "Ied dopet, s dwo  iou therl tr and banou.\n",
            "Ame- be s  sye? .\n",
            "Bwrkot fe'Ye onterermer s r tho s ms.\n",
            "Yhang!\n",
            "Le wokite llirir b \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "\n",
        "  print(evaluate(my_decoder, start_strings[start], 200), '\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}